{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"tic-tac-toe.data\", sep = \",\")\n",
    "data.rename(columns={'x': 'top-left-square', 'x.1': 'top-middle-square', 'x.2': 'top-right-square','x.3': 'middle-left-square', 'o': 'middle-middle-square', 'o.1' : 'middle-right-square', 'x.4' : 'bottom-left-square', 'o.2' : 'bottom-middle-square', 'o.3':'bottom-right-square','positive' : 'outcome'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top-left-square</th>\n",
       "      <th>top-middle-square</th>\n",
       "      <th>top-right-square</th>\n",
       "      <th>middle-left-square</th>\n",
       "      <th>middle-middle-square</th>\n",
       "      <th>middle-right-square</th>\n",
       "      <th>bottom-left-square</th>\n",
       "      <th>bottom-middle-square</th>\n",
       "      <th>bottom-right-square</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  top-left-square top-middle-square top-right-square middle-left-square  \\\n",
       "0               x                 x                x                  x   \n",
       "1               x                 x                x                  x   \n",
       "2               x                 x                x                  x   \n",
       "3               x                 x                x                  x   \n",
       "\n",
       "  middle-middle-square middle-right-square bottom-left-square  \\\n",
       "0                    o                   o                  o   \n",
       "1                    o                   o                  o   \n",
       "2                    o                   o                  o   \n",
       "3                    o                   o                  b   \n",
       "\n",
       "  bottom-middle-square bottom-right-square   outcome  \n",
       "0                    x                   o  positive  \n",
       "1                    o                   x  positive  \n",
       "2                    b                   b  positive  \n",
       "3                    o                   b  positive  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = pd.get_dummies(data.iloc[:,0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top-left-square_b</th>\n",
       "      <th>top-left-square_o</th>\n",
       "      <th>top-left-square_x</th>\n",
       "      <th>top-middle-square_b</th>\n",
       "      <th>top-middle-square_o</th>\n",
       "      <th>top-middle-square_x</th>\n",
       "      <th>top-right-square_b</th>\n",
       "      <th>top-right-square_o</th>\n",
       "      <th>top-right-square_x</th>\n",
       "      <th>middle-left-square_b</th>\n",
       "      <th>...</th>\n",
       "      <th>bottom-left-square_o</th>\n",
       "      <th>bottom-left-square_x</th>\n",
       "      <th>bottom-middle-square_b</th>\n",
       "      <th>bottom-middle-square_o</th>\n",
       "      <th>bottom-middle-square_x</th>\n",
       "      <th>bottom-right-square_b</th>\n",
       "      <th>bottom-right-square_o</th>\n",
       "      <th>bottom-right-square_x</th>\n",
       "      <th>outcome_negative</th>\n",
       "      <th>outcome_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   top-left-square_b  top-left-square_o  top-left-square_x  \\\n",
       "0                  0                  0                  1   \n",
       "1                  0                  0                  1   \n",
       "2                  0                  0                  1   \n",
       "3                  0                  0                  1   \n",
       "4                  0                  0                  1   \n",
       "5                  0                  0                  1   \n",
       "6                  0                  0                  1   \n",
       "\n",
       "   top-middle-square_b  top-middle-square_o  top-middle-square_x  \\\n",
       "0                    0                    0                    1   \n",
       "1                    0                    0                    1   \n",
       "2                    0                    0                    1   \n",
       "3                    0                    0                    1   \n",
       "4                    0                    0                    1   \n",
       "5                    0                    0                    1   \n",
       "6                    0                    0                    1   \n",
       "\n",
       "   top-right-square_b  top-right-square_o  top-right-square_x  \\\n",
       "0                   0                   0                   1   \n",
       "1                   0                   0                   1   \n",
       "2                   0                   0                   1   \n",
       "3                   0                   0                   1   \n",
       "4                   0                   0                   1   \n",
       "5                   0                   0                   1   \n",
       "6                   0                   0                   1   \n",
       "\n",
       "   middle-left-square_b        ...         bottom-left-square_o  \\\n",
       "0                     0        ...                            1   \n",
       "1                     0        ...                            1   \n",
       "2                     0        ...                            1   \n",
       "3                     0        ...                            0   \n",
       "4                     0        ...                            0   \n",
       "5                     0        ...                            1   \n",
       "6                     0        ...                            1   \n",
       "\n",
       "   bottom-left-square_x  bottom-middle-square_b  bottom-middle-square_o  \\\n",
       "0                     0                       0                       0   \n",
       "1                     0                       0                       1   \n",
       "2                     0                       1                       0   \n",
       "3                     0                       0                       1   \n",
       "4                     0                       1                       0   \n",
       "5                     0                       0                       1   \n",
       "6                     0                       1                       0   \n",
       "\n",
       "   bottom-middle-square_x  bottom-right-square_b  bottom-right-square_o  \\\n",
       "0                       1                      0                      1   \n",
       "1                       0                      0                      0   \n",
       "2                       0                      1                      0   \n",
       "3                       0                      1                      0   \n",
       "4                       0                      0                      1   \n",
       "5                       0                      1                      0   \n",
       "6                       0                      0                      1   \n",
       "\n",
       "   bottom-right-square_x  outcome_negative  outcome_positive  \n",
       "0                      0                 0                 1  \n",
       "1                      1                 0                 1  \n",
       "2                      0                 0                 1  \n",
       "3                      0                 0                 1  \n",
       "4                      0                 0                 1  \n",
       "5                      0                 0                 1  \n",
       "6                      0                 0                 1  \n",
       "\n",
       "[7 rows x 29 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.concat([data_new],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet, testSet = train_test_split(data_final,test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top-left-square_b</th>\n",
       "      <th>top-left-square_o</th>\n",
       "      <th>top-left-square_x</th>\n",
       "      <th>top-middle-square_b</th>\n",
       "      <th>top-middle-square_o</th>\n",
       "      <th>top-middle-square_x</th>\n",
       "      <th>top-right-square_b</th>\n",
       "      <th>top-right-square_o</th>\n",
       "      <th>top-right-square_x</th>\n",
       "      <th>middle-left-square_b</th>\n",
       "      <th>...</th>\n",
       "      <th>bottom-left-square_o</th>\n",
       "      <th>bottom-left-square_x</th>\n",
       "      <th>bottom-middle-square_b</th>\n",
       "      <th>bottom-middle-square_o</th>\n",
       "      <th>bottom-middle-square_x</th>\n",
       "      <th>bottom-right-square_b</th>\n",
       "      <th>bottom-right-square_o</th>\n",
       "      <th>bottom-right-square_x</th>\n",
       "      <th>outcome_negative</th>\n",
       "      <th>outcome_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     top-left-square_b  top-left-square_o  top-left-square_x  \\\n",
       "827                  0                  1                  0   \n",
       "805                  0                  1                  0   \n",
       "291                  0                  0                  1   \n",
       "642                  0                  0                  1   \n",
       "694                  0                  0                  1   \n",
       "72                   0                  0                  1   \n",
       "237                  0                  0                  1   \n",
       "\n",
       "     top-middle-square_b  top-middle-square_o  top-middle-square_x  \\\n",
       "827                    0                    1                    0   \n",
       "805                    0                    1                    0   \n",
       "291                    1                    0                    0   \n",
       "642                    0                    0                    1   \n",
       "694                    0                    1                    0   \n",
       "72                     0                    0                    1   \n",
       "237                    1                    0                    0   \n",
       "\n",
       "     top-right-square_b  top-right-square_o  top-right-square_x  \\\n",
       "827                   0                   1                   0   \n",
       "805                   0                   0                   1   \n",
       "291                   1                   0                   0   \n",
       "642                   0                   1                   0   \n",
       "694                   0                   1                   0   \n",
       "72                    0                   0                   1   \n",
       "237                   0                   0                   1   \n",
       "\n",
       "     middle-left-square_b        ...         bottom-left-square_o  \\\n",
       "827                     0        ...                            0   \n",
       "805                     0        ...                            0   \n",
       "291                     1        ...                            1   \n",
       "642                     0        ...                            0   \n",
       "694                     1        ...                            0   \n",
       "72                      1        ...                            0   \n",
       "237                     1        ...                            1   \n",
       "\n",
       "     bottom-left-square_x  bottom-middle-square_b  bottom-middle-square_o  \\\n",
       "827                     0                       1                       0   \n",
       "805                     1                       0                       0   \n",
       "291                     0                       1                       0   \n",
       "642                     1                       0                       0   \n",
       "694                     1                       0                       0   \n",
       "72                      0                       0                       1   \n",
       "237                     0                       0                       1   \n",
       "\n",
       "     bottom-middle-square_x  bottom-right-square_b  bottom-right-square_o  \\\n",
       "827                       0                      0                      0   \n",
       "805                       1                      0                      1   \n",
       "291                       0                      0                      0   \n",
       "642                       1                      1                      0   \n",
       "694                       1                      0                      1   \n",
       "72                        0                      1                      0   \n",
       "237                       0                      0                      0   \n",
       "\n",
       "     bottom-right-square_x  outcome_negative  outcome_positive  \n",
       "827                      1                 1                 0  \n",
       "805                      0                 1                 0  \n",
       "291                      1                 0                 1  \n",
       "642                      0                 1                 0  \n",
       "694                      0                 1                 0  \n",
       "72                       0                 0                 1  \n",
       "237                      1                 0                 1  \n",
       "\n",
       "[7 rows x 29 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogisReg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_trainSet = trainSet.iloc[:,:-1]\n",
    "y_trainSet = trainSet.iloc[:,-1]\n",
    "x_testSet = testSet.iloc[:,:-1]\n",
    "y_testSet = testSet.iloc[:,-1]\n",
    "LogisReg = LogisReg.fit(x_trainSet,y_trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset : \n",
      "number of samples_______ = 641\n",
      "number of wins for x____ = 427\n",
      "number of wins for o____ = 214\n"
     ]
    }
   ],
   "source": [
    "print('training dataset : ')\n",
    "print('{:_<24s} = {:d}'.format('number of samples', y_trainSet.shape[0]))\n",
    "print('{:_<24s} = {:d}'.format('number of wins for x', np.sum(y_trainSet == 1)))\n",
    "print('{:_<24s} = {:d}'.format('number of wins for o', np.sum(y_trainSet == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing dataset : \n",
      "number of samples_______ = 316\n",
      "number of wins for x____ = 198\n",
      "number of wins for 0____ = 118\n"
     ]
    }
   ],
   "source": [
    "print('testing dataset : ')\n",
    "print('{:_<24s} = {:d}'.format('number of samples', y_testSet.shape[0]))\n",
    "print('{:_<24s} = {:d}'.format('number of wins for x', np.sum(y_testSet == 1)))\n",
    "print('{:_<24s} = {:d}'.format('number of wins for 0', np.sum(y_testSet == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359    1\n",
       "543    1\n",
       "Name: outcome_positive, dtype: uint8"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "827    0\n",
       "805    0\n",
       "291    1\n",
       "642    0\n",
       "694    0\n",
       "72     1\n",
       "237    1\n",
       "Name: outcome_positive, dtype: uint8"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trainSet.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(x, weight):\n",
    "    z = np.dot(x, weight.T)\n",
    "    h = 1.0 / (1.0 + np.exp(-z))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x,y,weight):\n",
    "    #z = np.dot(x, weight.T)\n",
    "    N = y.shape[0]\n",
    "    loglike = 1.0/(2*N) * np.sum((h(x,weight)-y)**2)\n",
    "    #loglike = np.sum(y*z - np.log(1+np.exp(z)))\n",
    "    return loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(x,y,weight,learn_rate = 0.1,epsilon = 0.001,maxIteration = 1000):\n",
    "    y = y[:,np.newaxis]\n",
    "    N = y.shape[0]\n",
    "    i = 0\n",
    "    while True:\n",
    "        print('iteration{:>2d}, loss = {:>8f}'.format(i, cost(x,y,weight)))\n",
    "        weight_prev = weight.copy()\n",
    "        error = (h(x,weight)- y)\n",
    "        weight = weight - (learn_rate*1.0)/N * np.sum(error * x, axis=0)\n",
    "        i=i+1\n",
    "        if (np.max(np.abs(weight - weight_prev)) < epsilon) or (i > maxIteration):\n",
    "            break\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_trainSet = (x_trainSet - np.mean(x_trainSet, axis=0)) /np.std(x_trainSet, axis=0)\n",
    "x_testSet = (x_testSet - np.mean(x_trainSet, axis=0)) /np.std(x_trainSet, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainSet_aug = np.hstack((np.ones((x_trainSet.shape[0],1)), x_trainSet))\n",
    "x_testSet_aug = np.hstack((np.ones((x_testSet.shape[0],1)), x_testSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, loss = 0.169924\n",
      "iteration 1, loss = 0.167452\n",
      "iteration 2, loss = 0.164987\n",
      "iteration 3, loss = 0.162531\n",
      "iteration 4, loss = 0.160083\n",
      "iteration 5, loss = 0.157644\n",
      "iteration 6, loss = 0.155214\n",
      "iteration 7, loss = 0.152795\n",
      "iteration 8, loss = 0.150385\n",
      "iteration 9, loss = 0.147987\n",
      "iteration10, loss = 0.145600\n",
      "iteration11, loss = 0.143225\n",
      "iteration12, loss = 0.140863\n",
      "iteration13, loss = 0.138515\n",
      "iteration14, loss = 0.136180\n",
      "iteration15, loss = 0.133860\n",
      "iteration16, loss = 0.131555\n",
      "iteration17, loss = 0.129264\n",
      "iteration18, loss = 0.126989\n",
      "iteration19, loss = 0.124729\n",
      "iteration20, loss = 0.122485\n",
      "iteration21, loss = 0.120257\n",
      "iteration22, loss = 0.118043\n",
      "iteration23, loss = 0.115845\n",
      "iteration24, loss = 0.113662\n",
      "iteration25, loss = 0.111494\n",
      "iteration26, loss = 0.109340\n",
      "iteration27, loss = 0.107201\n",
      "iteration28, loss = 0.105076\n",
      "iteration29, loss = 0.102965\n",
      "iteration30, loss = 0.100867\n",
      "iteration31, loss = 0.098784\n",
      "iteration32, loss = 0.096716\n",
      "iteration33, loss = 0.094661\n",
      "iteration34, loss = 0.092621\n",
      "iteration35, loss = 0.090596\n",
      "iteration36, loss = 0.088587\n",
      "iteration37, loss = 0.086594\n",
      "iteration38, loss = 0.084617\n",
      "iteration39, loss = 0.082657\n",
      "iteration40, loss = 0.080715\n",
      "iteration41, loss = 0.078792\n",
      "iteration42, loss = 0.076887\n",
      "iteration43, loss = 0.075003\n",
      "iteration44, loss = 0.073139\n",
      "iteration45, loss = 0.071297\n",
      "iteration46, loss = 0.069476\n",
      "iteration47, loss = 0.067677\n",
      "iteration48, loss = 0.065901\n",
      "iteration49, loss = 0.064149\n",
      "iteration50, loss = 0.062421\n",
      "iteration51, loss = 0.060717\n",
      "iteration52, loss = 0.059037\n",
      "iteration53, loss = 0.057383\n",
      "iteration54, loss = 0.055754\n",
      "iteration55, loss = 0.054152\n",
      "iteration56, loss = 0.052575\n",
      "iteration57, loss = 0.051025\n",
      "iteration58, loss = 0.049503\n",
      "iteration59, loss = 0.048007\n",
      "iteration60, loss = 0.046540\n",
      "iteration61, loss = 0.045101\n",
      "iteration62, loss = 0.043690\n",
      "iteration63, loss = 0.042309\n",
      "iteration64, loss = 0.040957\n",
      "iteration65, loss = 0.039634\n",
      "iteration66, loss = 0.038341\n",
      "iteration67, loss = 0.037079\n",
      "iteration68, loss = 0.035847\n",
      "iteration69, loss = 0.034646\n",
      "iteration70, loss = 0.033476\n",
      "iteration71, loss = 0.032337\n",
      "iteration72, loss = 0.031228\n",
      "iteration73, loss = 0.030151\n",
      "iteration74, loss = 0.029105\n",
      "iteration75, loss = 0.028089\n",
      "iteration76, loss = 0.027104\n",
      "iteration77, loss = 0.026150\n",
      "iteration78, loss = 0.025225\n",
      "iteration79, loss = 0.024330\n",
      "iteration80, loss = 0.023465\n",
      "iteration81, loss = 0.022628\n",
      "iteration82, loss = 0.021820\n",
      "iteration83, loss = 0.021040\n",
      "iteration84, loss = 0.020287\n",
      "iteration85, loss = 0.019560\n",
      "iteration86, loss = 0.018860\n",
      "iteration87, loss = 0.018186\n",
      "iteration88, loss = 0.017536\n",
      "iteration89, loss = 0.016910\n",
      "iteration90, loss = 0.016308\n",
      "iteration91, loss = 0.015729\n",
      "iteration92, loss = 0.015171\n",
      "iteration93, loss = 0.014636\n",
      "iteration94, loss = 0.014120\n",
      "iteration95, loss = 0.013625\n",
      "iteration96, loss = 0.013149\n",
      "iteration97, loss = 0.012692\n",
      "iteration98, loss = 0.012253\n",
      "iteration99, loss = 0.011832\n",
      "iteration100, loss = 0.011426\n",
      "iteration101, loss = 0.011038\n",
      "iteration102, loss = 0.010664\n",
      "iteration103, loss = 0.010305\n",
      "iteration104, loss = 0.009961\n",
      "iteration105, loss = 0.009630\n",
      "iteration106, loss = 0.009313\n",
      "iteration107, loss = 0.009008\n",
      "iteration108, loss = 0.008715\n",
      "iteration109, loss = 0.008434\n",
      "iteration110, loss = 0.008164\n",
      "iteration111, loss = 0.007905\n",
      "iteration112, loss = 0.007656\n",
      "iteration113, loss = 0.007417\n",
      "iteration114, loss = 0.007187\n",
      "iteration115, loss = 0.006966\n",
      "iteration116, loss = 0.006754\n",
      "iteration117, loss = 0.006550\n",
      "iteration118, loss = 0.006354\n",
      "iteration119, loss = 0.006166\n",
      "iteration120, loss = 0.005984\n",
      "iteration121, loss = 0.005810\n",
      "iteration122, loss = 0.005643\n",
      "iteration123, loss = 0.005481\n",
      "iteration124, loss = 0.005326\n",
      "iteration125, loss = 0.005177\n",
      "iteration126, loss = 0.005033\n",
      "iteration127, loss = 0.004894\n",
      "iteration128, loss = 0.004761\n",
      "iteration129, loss = 0.004633\n",
      "iteration130, loss = 0.004509\n",
      "iteration131, loss = 0.004390\n",
      "iteration132, loss = 0.004275\n",
      "iteration133, loss = 0.004164\n",
      "iteration134, loss = 0.004057\n",
      "iteration135, loss = 0.003954\n",
      "iteration136, loss = 0.003854\n",
      "iteration137, loss = 0.003758\n",
      "iteration138, loss = 0.003665\n",
      "iteration139, loss = 0.003576\n",
      "iteration140, loss = 0.003489\n",
      "iteration141, loss = 0.003406\n",
      "iteration142, loss = 0.003325\n",
      "iteration143, loss = 0.003247\n",
      "iteration144, loss = 0.003172\n",
      "iteration145, loss = 0.003099\n",
      "iteration146, loss = 0.003029\n",
      "iteration147, loss = 0.002960\n",
      "iteration148, loss = 0.002894\n",
      "iteration149, loss = 0.002830\n",
      "iteration150, loss = 0.002769\n",
      "iteration151, loss = 0.002709\n",
      "iteration152, loss = 0.002651\n",
      "iteration153, loss = 0.002594\n",
      "iteration154, loss = 0.002540\n",
      "iteration155, loss = 0.002487\n",
      "iteration156, loss = 0.002436\n",
      "iteration157, loss = 0.002386\n",
      "iteration158, loss = 0.002338\n",
      "iteration159, loss = 0.002292\n",
      "iteration160, loss = 0.002246\n",
      "iteration161, loss = 0.002202\n",
      "iteration162, loss = 0.002159\n",
      "iteration163, loss = 0.002118\n",
      "iteration164, loss = 0.002078\n",
      "iteration165, loss = 0.002038\n",
      "iteration166, loss = 0.002000\n",
      "iteration167, loss = 0.001963\n",
      "iteration168, loss = 0.001927\n",
      "iteration169, loss = 0.001893\n",
      "iteration170, loss = 0.001858\n",
      "iteration171, loss = 0.001825\n",
      "iteration172, loss = 0.001793\n",
      "iteration173, loss = 0.001762\n",
      "iteration174, loss = 0.001731\n",
      "iteration175, loss = 0.001702\n",
      "iteration176, loss = 0.001673\n",
      "iteration177, loss = 0.001645\n",
      "iteration178, loss = 0.001617\n",
      "iteration179, loss = 0.001590\n",
      "iteration180, loss = 0.001564\n",
      "iteration181, loss = 0.001539\n",
      "iteration182, loss = 0.001514\n",
      "iteration183, loss = 0.001490\n",
      "iteration184, loss = 0.001466\n",
      "iteration185, loss = 0.001443\n",
      "iteration186, loss = 0.001421\n",
      "iteration187, loss = 0.001399\n",
      "iteration188, loss = 0.001378\n",
      "iteration189, loss = 0.001357\n",
      "iteration190, loss = 0.001336\n",
      "iteration191, loss = 0.001316\n",
      "iteration192, loss = 0.001297\n",
      "iteration193, loss = 0.001278\n",
      "iteration194, loss = 0.001259\n",
      "iteration195, loss = 0.001241\n",
      "iteration196, loss = 0.001224\n",
      "iteration197, loss = 0.001206\n",
      "iteration198, loss = 0.001189\n",
      "iteration199, loss = 0.001173\n",
      "iteration200, loss = 0.001156\n",
      "iteration201, loss = 0.001141\n",
      "iteration202, loss = 0.001125\n",
      "iteration203, loss = 0.001110\n",
      "iteration204, loss = 0.001095\n",
      "iteration205, loss = 0.001080\n",
      "iteration206, loss = 0.001066\n",
      "iteration207, loss = 0.001052\n",
      "iteration208, loss = 0.001039\n",
      "iteration209, loss = 0.001025\n",
      "iteration210, loss = 0.001012\n",
      "iteration211, loss = 0.000999\n",
      "iteration212, loss = 0.000987\n",
      "iteration213, loss = 0.000974\n",
      "iteration214, loss = 0.000962\n",
      "iteration215, loss = 0.000950\n",
      "iteration216, loss = 0.000939\n",
      "iteration217, loss = 0.000927\n",
      "iteration218, loss = 0.000916\n",
      "iteration219, loss = 0.000905\n",
      "iteration220, loss = 0.000894\n",
      "iteration221, loss = 0.000884\n",
      "iteration222, loss = 0.000873\n",
      "iteration223, loss = 0.000863\n",
      "iteration224, loss = 0.000853\n",
      "iteration225, loss = 0.000843\n",
      "iteration226, loss = 0.000834\n",
      "iteration227, loss = 0.000824\n",
      "iteration228, loss = 0.000815\n",
      "iteration229, loss = 0.000806\n",
      "iteration230, loss = 0.000797\n",
      "iteration231, loss = 0.000788\n",
      "iteration232, loss = 0.000780\n",
      "iteration233, loss = 0.000771\n",
      "iteration234, loss = 0.000763\n",
      "iteration235, loss = 0.000755\n",
      "iteration236, loss = 0.000747\n",
      "iteration237, loss = 0.000739\n",
      "iteration238, loss = 0.000731\n",
      "iteration239, loss = 0.000723\n",
      "iteration240, loss = 0.000716\n",
      "iteration241, loss = 0.000709\n",
      "iteration242, loss = 0.000701\n",
      "iteration243, loss = 0.000694\n",
      "iteration244, loss = 0.000687\n",
      "iteration245, loss = 0.000680\n",
      "iteration246, loss = 0.000673\n",
      "iteration247, loss = 0.000667\n",
      "iteration248, loss = 0.000660\n",
      "iteration249, loss = 0.000654\n",
      "iteration250, loss = 0.000647\n",
      "iteration251, loss = 0.000641\n",
      "iteration252, loss = 0.000635\n",
      "iteration253, loss = 0.000629\n",
      "iteration254, loss = 0.000623\n",
      "iteration255, loss = 0.000617\n",
      "iteration256, loss = 0.000611\n",
      "iteration257, loss = 0.000605\n",
      "iteration258, loss = 0.000600\n",
      "iteration259, loss = 0.000594\n",
      "iteration260, loss = 0.000589\n",
      "iteration261, loss = 0.000583\n",
      "iteration262, loss = 0.000578\n",
      "iteration263, loss = 0.000573\n",
      "iteration264, loss = 0.000568\n",
      "iteration265, loss = 0.000562\n",
      "iteration266, loss = 0.000557\n",
      "iteration267, loss = 0.000553\n",
      "iteration268, loss = 0.000548\n",
      "iteration269, loss = 0.000543\n",
      "iteration270, loss = 0.000538\n",
      "iteration271, loss = 0.000534\n",
      "iteration272, loss = 0.000529\n",
      "iteration273, loss = 0.000524\n",
      "iteration274, loss = 0.000520\n",
      "iteration275, loss = 0.000516\n",
      "iteration276, loss = 0.000511\n",
      "iteration277, loss = 0.000507\n",
      "iteration278, loss = 0.000503\n",
      "iteration279, loss = 0.000499\n",
      "iteration280, loss = 0.000494\n",
      "iteration281, loss = 0.000490\n",
      "iteration282, loss = 0.000486\n",
      "iteration283, loss = 0.000482\n",
      "iteration284, loss = 0.000479\n",
      "iteration285, loss = 0.000475\n",
      "iteration286, loss = 0.000471\n",
      "iteration287, loss = 0.000467\n",
      "iteration288, loss = 0.000463\n",
      "iteration289, loss = 0.000460\n",
      "iteration290, loss = 0.000456\n",
      "iteration291, loss = 0.000453\n",
      "iteration292, loss = 0.000449\n",
      "iteration293, loss = 0.000446\n",
      "iteration294, loss = 0.000442\n",
      "iteration295, loss = 0.000439\n",
      "iteration296, loss = 0.000435\n",
      "iteration297, loss = 0.000432\n",
      "iteration298, loss = 0.000429\n",
      "iteration299, loss = 0.000426\n",
      "iteration300, loss = 0.000423\n",
      "iteration301, loss = 0.000419\n",
      "iteration302, loss = 0.000416\n",
      "iteration303, loss = 0.000413\n",
      "iteration304, loss = 0.000410\n",
      "iteration305, loss = 0.000407\n",
      "iteration306, loss = 0.000404\n",
      "iteration307, loss = 0.000401\n",
      "iteration308, loss = 0.000398\n",
      "iteration309, loss = 0.000396\n",
      "iteration310, loss = 0.000393\n",
      "iteration311, loss = 0.000390\n",
      "iteration312, loss = 0.000387\n",
      "iteration313, loss = 0.000384\n",
      "iteration314, loss = 0.000382\n",
      "iteration315, loss = 0.000379\n",
      "iteration316, loss = 0.000376\n",
      "iteration317, loss = 0.000374\n",
      "iteration318, loss = 0.000371\n",
      "iteration319, loss = 0.000369\n",
      "iteration320, loss = 0.000366\n",
      "iteration321, loss = 0.000364\n",
      "iteration322, loss = 0.000361\n",
      "iteration323, loss = 0.000359\n",
      "iteration324, loss = 0.000356\n",
      "iteration325, loss = 0.000354\n",
      "iteration326, loss = 0.000352\n",
      "iteration327, loss = 0.000349\n",
      "iteration328, loss = 0.000347\n",
      "iteration329, loss = 0.000345\n",
      "iteration330, loss = 0.000343\n",
      "iteration331, loss = 0.000340\n",
      "iteration332, loss = 0.000338\n",
      "iteration333, loss = 0.000336\n",
      "iteration334, loss = 0.000334\n",
      "iteration335, loss = 0.000332\n",
      "iteration336, loss = 0.000329\n",
      "iteration337, loss = 0.000327\n",
      "iteration338, loss = 0.000325\n",
      "iteration339, loss = 0.000323\n",
      "iteration340, loss = 0.000321\n",
      "iteration341, loss = 0.000319\n",
      "iteration342, loss = 0.000317\n",
      "iteration343, loss = 0.000315\n",
      "iteration344, loss = 0.000313\n",
      "iteration345, loss = 0.000311\n",
      "iteration346, loss = 0.000309\n",
      "iteration347, loss = 0.000308\n",
      "iteration348, loss = 0.000306\n",
      "iteration349, loss = 0.000304\n",
      "iteration350, loss = 0.000302\n",
      "iteration351, loss = 0.000300\n",
      "iteration352, loss = 0.000298\n",
      "iteration353, loss = 0.000297\n",
      "iteration354, loss = 0.000295\n",
      "iteration355, loss = 0.000293\n",
      "iteration356, loss = 0.000291\n",
      "iteration357, loss = 0.000290\n",
      "iteration358, loss = 0.000288\n",
      "iteration359, loss = 0.000286\n",
      "iteration360, loss = 0.000285\n",
      "iteration361, loss = 0.000283\n",
      "iteration362, loss = 0.000281\n",
      "iteration363, loss = 0.000280\n",
      "iteration364, loss = 0.000278\n",
      "iteration365, loss = 0.000276\n",
      "iteration366, loss = 0.000275\n",
      "iteration367, loss = 0.000273\n",
      "iteration368, loss = 0.000272\n",
      "iteration369, loss = 0.000270\n",
      "iteration370, loss = 0.000269\n",
      "iteration371, loss = 0.000267\n",
      "iteration372, loss = 0.000266\n",
      "iteration373, loss = 0.000264\n",
      "iteration374, loss = 0.000263\n",
      "iteration375, loss = 0.000261\n",
      "iteration376, loss = 0.000260\n",
      "iteration377, loss = 0.000258\n",
      "iteration378, loss = 0.000257\n",
      "iteration379, loss = 0.000256\n",
      "iteration380, loss = 0.000254\n",
      "iteration381, loss = 0.000253\n",
      "iteration382, loss = 0.000252\n",
      "iteration383, loss = 0.000250\n",
      "iteration384, loss = 0.000249\n",
      "iteration385, loss = 0.000248\n",
      "iteration386, loss = 0.000246\n",
      "iteration387, loss = 0.000245\n",
      "iteration388, loss = 0.000244\n",
      "iteration389, loss = 0.000242\n",
      "iteration390, loss = 0.000241\n",
      "iteration391, loss = 0.000240\n",
      "iteration392, loss = 0.000239\n",
      "iteration393, loss = 0.000237\n",
      "iteration394, loss = 0.000236\n",
      "iteration395, loss = 0.000235\n",
      "iteration396, loss = 0.000234\n",
      "iteration397, loss = 0.000232\n",
      "iteration398, loss = 0.000231\n",
      "iteration399, loss = 0.000230\n",
      "iteration400, loss = 0.000229\n",
      "iteration401, loss = 0.000228\n",
      "iteration402, loss = 0.000227\n",
      "iteration403, loss = 0.000225\n",
      "iteration404, loss = 0.000224\n",
      "iteration405, loss = 0.000223\n",
      "iteration406, loss = 0.000222\n",
      "iteration407, loss = 0.000221\n",
      "iteration408, loss = 0.000220\n",
      "iteration409, loss = 0.000219\n",
      "iteration410, loss = 0.000218\n",
      "iteration411, loss = 0.000217\n",
      "iteration412, loss = 0.000216\n",
      "iteration413, loss = 0.000215\n",
      "iteration414, loss = 0.000214\n",
      "iteration415, loss = 0.000213\n",
      "iteration416, loss = 0.000211\n",
      "iteration417, loss = 0.000210\n",
      "iteration418, loss = 0.000209\n",
      "iteration419, loss = 0.000208\n",
      "iteration420, loss = 0.000207\n",
      "iteration421, loss = 0.000206\n",
      "iteration422, loss = 0.000205\n",
      "iteration423, loss = 0.000205\n",
      "iteration424, loss = 0.000204\n",
      "iteration425, loss = 0.000203\n",
      "iteration426, loss = 0.000202\n",
      "iteration427, loss = 0.000201\n",
      "iteration428, loss = 0.000200\n",
      "iteration429, loss = 0.000199\n",
      "iteration430, loss = 0.000198\n",
      "iteration431, loss = 0.000197\n",
      "iteration432, loss = 0.000196\n",
      "iteration433, loss = 0.000195\n",
      "iteration434, loss = 0.000194\n",
      "iteration435, loss = 0.000193\n",
      "iteration436, loss = 0.000193\n",
      "iteration437, loss = 0.000192\n",
      "iteration438, loss = 0.000191\n",
      "iteration439, loss = 0.000190\n",
      "iteration440, loss = 0.000189\n",
      "iteration441, loss = 0.000188\n",
      "iteration442, loss = 0.000187\n",
      "iteration443, loss = 0.000187\n",
      "iteration444, loss = 0.000186\n",
      "iteration445, loss = 0.000185\n",
      "iteration446, loss = 0.000184\n",
      "iteration447, loss = 0.000183\n",
      "iteration448, loss = 0.000182\n",
      "iteration449, loss = 0.000182\n",
      "iteration450, loss = 0.000181\n",
      "iteration451, loss = 0.000180\n",
      "iteration452, loss = 0.000179\n",
      "iteration453, loss = 0.000178\n",
      "iteration454, loss = 0.000178\n",
      "iteration455, loss = 0.000177\n",
      "iteration456, loss = 0.000176\n",
      "iteration457, loss = 0.000175\n",
      "iteration458, loss = 0.000175\n",
      "iteration459, loss = 0.000174\n",
      "iteration460, loss = 0.000173\n",
      "iteration461, loss = 0.000172\n",
      "iteration462, loss = 0.000172\n",
      "iteration463, loss = 0.000171\n",
      "iteration464, loss = 0.000170\n",
      "iteration465, loss = 0.000170\n",
      "iteration466, loss = 0.000169\n",
      "iteration467, loss = 0.000168\n",
      "iteration468, loss = 0.000167\n",
      "iteration469, loss = 0.000167\n",
      "iteration470, loss = 0.000166\n",
      "iteration471, loss = 0.000165\n",
      "iteration472, loss = 0.000165\n",
      "iteration473, loss = 0.000164\n",
      "iteration474, loss = 0.000163\n",
      "iteration475, loss = 0.000163\n",
      "iteration476, loss = 0.000162\n",
      "iteration477, loss = 0.000161\n",
      "iteration478, loss = 0.000161\n",
      "iteration479, loss = 0.000160\n",
      "iteration480, loss = 0.000159\n",
      "iteration481, loss = 0.000159\n",
      "iteration482, loss = 0.000158\n",
      "iteration483, loss = 0.000157\n",
      "iteration484, loss = 0.000157\n",
      "iteration485, loss = 0.000156\n",
      "iteration486, loss = 0.000156\n",
      "iteration487, loss = 0.000155\n",
      "iteration488, loss = 0.000154\n",
      "iteration489, loss = 0.000154\n",
      "iteration490, loss = 0.000153\n",
      "iteration491, loss = 0.000152\n",
      "iteration492, loss = 0.000152\n",
      "iteration493, loss = 0.000151\n",
      "iteration494, loss = 0.000151\n",
      "iteration495, loss = 0.000150\n",
      "iteration496, loss = 0.000150\n",
      "iteration497, loss = 0.000149\n",
      "iteration498, loss = 0.000148\n",
      "iteration499, loss = 0.000148\n",
      "iteration500, loss = 0.000147\n",
      "iteration501, loss = 0.000147\n",
      "iteration502, loss = 0.000146\n",
      "iteration503, loss = 0.000146\n",
      "iteration504, loss = 0.000145\n",
      "iteration505, loss = 0.000144\n",
      "iteration506, loss = 0.000144\n",
      "iteration507, loss = 0.000143\n",
      "iteration508, loss = 0.000143\n",
      "iteration509, loss = 0.000142\n",
      "iteration510, loss = 0.000142\n",
      "iteration511, loss = 0.000141\n",
      "iteration512, loss = 0.000141\n",
      "iteration513, loss = 0.000140\n",
      "iteration514, loss = 0.000140\n",
      "iteration515, loss = 0.000139\n",
      "iteration516, loss = 0.000139\n",
      "iteration517, loss = 0.000138\n",
      "iteration518, loss = 0.000138\n",
      "iteration519, loss = 0.000137\n",
      "iteration520, loss = 0.000137\n",
      "iteration521, loss = 0.000136\n",
      "iteration522, loss = 0.000136\n",
      "iteration523, loss = 0.000135\n",
      "iteration524, loss = 0.000135\n",
      "iteration525, loss = 0.000134\n",
      "iteration526, loss = 0.000134\n",
      "iteration527, loss = 0.000133\n",
      "iteration528, loss = 0.000133\n",
      "iteration529, loss = 0.000132\n",
      "iteration530, loss = 0.000132\n",
      "iteration531, loss = 0.000131\n",
      "iteration532, loss = 0.000131\n",
      "iteration533, loss = 0.000130\n",
      "iteration534, loss = 0.000130\n",
      "iteration535, loss = 0.000129\n",
      "iteration536, loss = 0.000129\n",
      "iteration537, loss = 0.000128\n",
      "iteration538, loss = 0.000128\n",
      "iteration539, loss = 0.000127\n",
      "iteration540, loss = 0.000127\n",
      "iteration541, loss = 0.000127\n",
      "iteration542, loss = 0.000126\n",
      "iteration543, loss = 0.000126\n",
      "iteration544, loss = 0.000125\n",
      "iteration545, loss = 0.000125\n",
      "iteration546, loss = 0.000124\n",
      "iteration547, loss = 0.000124\n",
      "iteration548, loss = 0.000124\n",
      "iteration549, loss = 0.000123\n",
      "iteration550, loss = 0.000123\n",
      "iteration551, loss = 0.000122\n",
      "iteration552, loss = 0.000122\n",
      "iteration553, loss = 0.000121\n",
      "iteration554, loss = 0.000121\n",
      "iteration555, loss = 0.000121\n",
      "iteration556, loss = 0.000120\n",
      "iteration557, loss = 0.000120\n",
      "iteration558, loss = 0.000119\n",
      "iteration559, loss = 0.000119\n",
      "iteration560, loss = 0.000119\n",
      "iteration561, loss = 0.000118\n",
      "iteration562, loss = 0.000118\n",
      "iteration563, loss = 0.000117\n",
      "iteration564, loss = 0.000117\n",
      "iteration565, loss = 0.000117\n",
      "iteration566, loss = 0.000116\n",
      "iteration567, loss = 0.000116\n",
      "iteration568, loss = 0.000115\n",
      "iteration569, loss = 0.000115\n",
      "iteration570, loss = 0.000115\n",
      "iteration571, loss = 0.000114\n",
      "iteration572, loss = 0.000114\n",
      "iteration573, loss = 0.000113\n",
      "iteration574, loss = 0.000113\n",
      "iteration575, loss = 0.000113\n",
      "iteration576, loss = 0.000112\n",
      "iteration577, loss = 0.000112\n",
      "iteration578, loss = 0.000112\n",
      "iteration579, loss = 0.000111\n",
      "iteration580, loss = 0.000111\n",
      "iteration581, loss = 0.000111\n",
      "iteration582, loss = 0.000110\n",
      "iteration583, loss = 0.000110\n",
      "iteration584, loss = 0.000109\n",
      "iteration585, loss = 0.000109\n",
      "iteration586, loss = 0.000109\n",
      "iteration587, loss = 0.000108\n",
      "iteration588, loss = 0.000108\n",
      "iteration589, loss = 0.000108\n",
      "iteration590, loss = 0.000107\n",
      "iteration591, loss = 0.000107\n",
      "iteration592, loss = 0.000107\n",
      "iteration593, loss = 0.000106\n",
      "iteration594, loss = 0.000106\n",
      "iteration595, loss = 0.000106\n",
      "iteration596, loss = 0.000105\n",
      "iteration597, loss = 0.000105\n",
      "iteration598, loss = 0.000105\n",
      "iteration599, loss = 0.000104\n",
      "iteration600, loss = 0.000104\n",
      "iteration601, loss = 0.000104\n",
      "iteration602, loss = 0.000103\n",
      "iteration603, loss = 0.000103\n",
      "iteration604, loss = 0.000103\n",
      "iteration605, loss = 0.000102\n",
      "iteration606, loss = 0.000102\n",
      "iteration607, loss = 0.000102\n",
      "iteration608, loss = 0.000102\n",
      "iteration609, loss = 0.000101\n",
      "iteration610, loss = 0.000101\n",
      "iteration611, loss = 0.000101\n",
      "iteration612, loss = 0.000100\n",
      "iteration613, loss = 0.000100\n",
      "iteration614, loss = 0.000100\n",
      "iteration615, loss = 0.000099\n",
      "iteration616, loss = 0.000099\n",
      "iteration617, loss = 0.000099\n",
      "iteration618, loss = 0.000098\n",
      "iteration619, loss = 0.000098\n",
      "iteration620, loss = 0.000098\n",
      "iteration621, loss = 0.000098\n",
      "iteration622, loss = 0.000097\n",
      "iteration623, loss = 0.000097\n",
      "iteration624, loss = 0.000097\n",
      "iteration625, loss = 0.000096\n",
      "iteration626, loss = 0.000096\n",
      "iteration627, loss = 0.000096\n",
      "iteration628, loss = 0.000096\n",
      "iteration629, loss = 0.000095\n",
      "iteration630, loss = 0.000095\n",
      "iteration631, loss = 0.000095\n",
      "iteration632, loss = 0.000094\n",
      "iteration633, loss = 0.000094\n",
      "iteration634, loss = 0.000094\n",
      "iteration635, loss = 0.000094\n",
      "iteration636, loss = 0.000093\n",
      "iteration637, loss = 0.000093\n",
      "iteration638, loss = 0.000093\n",
      "iteration639, loss = 0.000093\n",
      "iteration640, loss = 0.000092\n",
      "iteration641, loss = 0.000092\n",
      "iteration642, loss = 0.000092\n",
      "iteration643, loss = 0.000091\n",
      "iteration644, loss = 0.000091\n",
      "iteration645, loss = 0.000091\n",
      "iteration646, loss = 0.000091\n",
      "iteration647, loss = 0.000090\n",
      "iteration648, loss = 0.000090\n",
      "iteration649, loss = 0.000090\n",
      "iteration650, loss = 0.000090\n",
      "iteration651, loss = 0.000089\n",
      "iteration652, loss = 0.000089\n",
      "iteration653, loss = 0.000089\n",
      "iteration654, loss = 0.000089\n",
      "iteration655, loss = 0.000088\n",
      "iteration656, loss = 0.000088\n",
      "iteration657, loss = 0.000088\n",
      "iteration658, loss = 0.000088\n",
      "iteration659, loss = 0.000087\n",
      "iteration660, loss = 0.000087\n",
      "iteration661, loss = 0.000087\n",
      "iteration662, loss = 0.000087\n",
      "iteration663, loss = 0.000086\n",
      "iteration664, loss = 0.000086\n",
      "iteration665, loss = 0.000086\n",
      "iteration666, loss = 0.000086\n",
      "iteration667, loss = 0.000085\n",
      "iteration668, loss = 0.000085\n",
      "iteration669, loss = 0.000085\n",
      "iteration670, loss = 0.000085\n",
      "iteration671, loss = 0.000084\n",
      "iteration672, loss = 0.000084\n",
      "iteration673, loss = 0.000084\n",
      "iteration674, loss = 0.000084\n",
      "iteration675, loss = 0.000084\n"
     ]
    }
   ],
   "source": [
    "weight = np.random.randn(1, x_trainSet_aug.shape[1])\n",
    "weight = logisticRegression(x_trainSet_aug, y_trainSet, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression test error = 0.0000\n"
     ]
    }
   ],
   "source": [
    "y_predict = (h(x_testSet_aug, weight) >= 0.5) [:,0]\n",
    "test_error = np.sum(y_testSet != y_predict) / y_testSet.shape[0]\n",
    "print('logistic regression test error = {:.4f}'.format(test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "probability = LogisReg.predict_proba(x_testSet)\n",
    "predicted = LogisReg.predict(x_testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118   0]\n",
      " [  0 198]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_testSet, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
