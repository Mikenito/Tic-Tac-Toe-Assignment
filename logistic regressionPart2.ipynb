{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"tic-tac-toe.data\", sep = \",\")\n",
    "data.rename(columns={'x': 'top-left-square', 'x.1': 'top-middle-square', 'x.2': 'top-right-square','x.3': 'middle-left-square', 'o': 'middle-middle-square', 'o.1' : 'middle-right-square', 'x.4' : 'bottom-left-square', 'o.2' : 'bottom-middle-square', 'o.3':'bottom-right-square','positive' : 'outcome'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top-left-square</th>\n",
       "      <th>top-middle-square</th>\n",
       "      <th>top-right-square</th>\n",
       "      <th>middle-left-square</th>\n",
       "      <th>middle-middle-square</th>\n",
       "      <th>middle-right-square</th>\n",
       "      <th>bottom-left-square</th>\n",
       "      <th>bottom-middle-square</th>\n",
       "      <th>bottom-right-square</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  top-left-square top-middle-square top-right-square middle-left-square  \\\n",
       "0               x                 x                x                  x   \n",
       "1               x                 x                x                  x   \n",
       "2               x                 x                x                  x   \n",
       "3               x                 x                x                  x   \n",
       "\n",
       "  middle-middle-square middle-right-square bottom-left-square  \\\n",
       "0                    o                   o                  o   \n",
       "1                    o                   o                  o   \n",
       "2                    o                   o                  o   \n",
       "3                    o                   o                  b   \n",
       "\n",
       "  bottom-middle-square bottom-right-square   outcome  \n",
       "0                    x                   o  positive  \n",
       "1                    o                   x  positive  \n",
       "2                    b                   b  positive  \n",
       "3                    o                   b  positive  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = pd.get_dummies(data.iloc[:,0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top-left-square_b</th>\n",
       "      <th>top-left-square_o</th>\n",
       "      <th>top-left-square_x</th>\n",
       "      <th>top-middle-square_b</th>\n",
       "      <th>top-middle-square_o</th>\n",
       "      <th>top-middle-square_x</th>\n",
       "      <th>top-right-square_b</th>\n",
       "      <th>top-right-square_o</th>\n",
       "      <th>top-right-square_x</th>\n",
       "      <th>middle-left-square_b</th>\n",
       "      <th>...</th>\n",
       "      <th>bottom-left-square_o</th>\n",
       "      <th>bottom-left-square_x</th>\n",
       "      <th>bottom-middle-square_b</th>\n",
       "      <th>bottom-middle-square_o</th>\n",
       "      <th>bottom-middle-square_x</th>\n",
       "      <th>bottom-right-square_b</th>\n",
       "      <th>bottom-right-square_o</th>\n",
       "      <th>bottom-right-square_x</th>\n",
       "      <th>outcome_negative</th>\n",
       "      <th>outcome_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   top-left-square_b  top-left-square_o  top-left-square_x  \\\n",
       "0                  0                  0                  1   \n",
       "1                  0                  0                  1   \n",
       "2                  0                  0                  1   \n",
       "3                  0                  0                  1   \n",
       "4                  0                  0                  1   \n",
       "5                  0                  0                  1   \n",
       "6                  0                  0                  1   \n",
       "\n",
       "   top-middle-square_b  top-middle-square_o  top-middle-square_x  \\\n",
       "0                    0                    0                    1   \n",
       "1                    0                    0                    1   \n",
       "2                    0                    0                    1   \n",
       "3                    0                    0                    1   \n",
       "4                    0                    0                    1   \n",
       "5                    0                    0                    1   \n",
       "6                    0                    0                    1   \n",
       "\n",
       "   top-right-square_b  top-right-square_o  top-right-square_x  \\\n",
       "0                   0                   0                   1   \n",
       "1                   0                   0                   1   \n",
       "2                   0                   0                   1   \n",
       "3                   0                   0                   1   \n",
       "4                   0                   0                   1   \n",
       "5                   0                   0                   1   \n",
       "6                   0                   0                   1   \n",
       "\n",
       "   middle-left-square_b        ...         bottom-left-square_o  \\\n",
       "0                     0        ...                            1   \n",
       "1                     0        ...                            1   \n",
       "2                     0        ...                            1   \n",
       "3                     0        ...                            0   \n",
       "4                     0        ...                            0   \n",
       "5                     0        ...                            1   \n",
       "6                     0        ...                            1   \n",
       "\n",
       "   bottom-left-square_x  bottom-middle-square_b  bottom-middle-square_o  \\\n",
       "0                     0                       0                       0   \n",
       "1                     0                       0                       1   \n",
       "2                     0                       1                       0   \n",
       "3                     0                       0                       1   \n",
       "4                     0                       1                       0   \n",
       "5                     0                       0                       1   \n",
       "6                     0                       1                       0   \n",
       "\n",
       "   bottom-middle-square_x  bottom-right-square_b  bottom-right-square_o  \\\n",
       "0                       1                      0                      1   \n",
       "1                       0                      0                      0   \n",
       "2                       0                      1                      0   \n",
       "3                       0                      1                      0   \n",
       "4                       0                      0                      1   \n",
       "5                       0                      1                      0   \n",
       "6                       0                      0                      1   \n",
       "\n",
       "   bottom-right-square_x  outcome_negative  outcome_positive  \n",
       "0                      0                 0                 1  \n",
       "1                      1                 0                 1  \n",
       "2                      0                 0                 1  \n",
       "3                      0                 0                 1  \n",
       "4                      0                 0                 1  \n",
       "5                      0                 0                 1  \n",
       "6                      0                 0                 1  \n",
       "\n",
       "[7 rows x 29 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.concat([data_new],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet, testSet = train_test_split(data_final,test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top-left-square_b</th>\n",
       "      <th>top-left-square_o</th>\n",
       "      <th>top-left-square_x</th>\n",
       "      <th>top-middle-square_b</th>\n",
       "      <th>top-middle-square_o</th>\n",
       "      <th>top-middle-square_x</th>\n",
       "      <th>top-right-square_b</th>\n",
       "      <th>top-right-square_o</th>\n",
       "      <th>top-right-square_x</th>\n",
       "      <th>middle-left-square_b</th>\n",
       "      <th>...</th>\n",
       "      <th>bottom-left-square_o</th>\n",
       "      <th>bottom-left-square_x</th>\n",
       "      <th>bottom-middle-square_b</th>\n",
       "      <th>bottom-middle-square_o</th>\n",
       "      <th>bottom-middle-square_x</th>\n",
       "      <th>bottom-right-square_b</th>\n",
       "      <th>bottom-right-square_o</th>\n",
       "      <th>bottom-right-square_x</th>\n",
       "      <th>outcome_negative</th>\n",
       "      <th>outcome_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     top-left-square_b  top-left-square_o  top-left-square_x  \\\n",
       "111                  0                  0                  1   \n",
       "43                   0                  0                  1   \n",
       "742                  0                  1                  0   \n",
       "179                  0                  0                  1   \n",
       "330                  0                  1                  0   \n",
       "638                  0                  0                  1   \n",
       "454                  0                  1                  0   \n",
       "\n",
       "     top-middle-square_b  top-middle-square_o  top-middle-square_x  \\\n",
       "111                    0                    0                    1   \n",
       "43                     0                    0                    1   \n",
       "742                    0                    0                    1   \n",
       "179                    0                    1                    0   \n",
       "330                    0                    0                    1   \n",
       "638                    0                    0                    1   \n",
       "454                    1                    0                    0   \n",
       "\n",
       "     top-right-square_b  top-right-square_o  top-right-square_x  \\\n",
       "111                   1                   0                   0   \n",
       "43                    0                   0                   1   \n",
       "742                   0                   0                   1   \n",
       "179                   0                   1                   0   \n",
       "330                   0                   1                   0   \n",
       "638                   0                   1                   0   \n",
       "454                   0                   0                   1   \n",
       "\n",
       "     middle-left-square_b        ...         bottom-left-square_o  \\\n",
       "111                     1        ...                            1   \n",
       "43                      0        ...                            0   \n",
       "742                     0        ...                            0   \n",
       "179                     1        ...                            0   \n",
       "330                     0        ...                            0   \n",
       "638                     0        ...                            0   \n",
       "454                     1        ...                            0   \n",
       "\n",
       "     bottom-left-square_x  bottom-middle-square_b  bottom-middle-square_o  \\\n",
       "111                     0                       0                       1   \n",
       "43                      1                       0                       1   \n",
       "742                     1                       1                       0   \n",
       "179                     1                       1                       0   \n",
       "330                     1                       0                       0   \n",
       "638                     0                       1                       0   \n",
       "454                     1                       0                       0   \n",
       "\n",
       "     bottom-middle-square_x  bottom-right-square_b  bottom-right-square_o  \\\n",
       "111                       0                      0                      0   \n",
       "43                        0                      0                      1   \n",
       "742                       0                      0                      1   \n",
       "179                       0                      0                      0   \n",
       "330                       1                      0                      0   \n",
       "638                       0                      0                      1   \n",
       "454                       1                      0                      0   \n",
       "\n",
       "     bottom-right-square_x  outcome_negative  outcome_positive  \n",
       "111                      1                 0                 1  \n",
       "43                       0                 0                 1  \n",
       "742                      0                 1                 0  \n",
       "179                      1                 0                 1  \n",
       "330                      1                 0                 1  \n",
       "638                      0                 1                 0  \n",
       "454                      1                 0                 1  \n",
       "\n",
       "[7 rows x 29 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogisReg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_trainSet = trainSet.iloc[:,:-1]\n",
    "y_trainSet = trainSet.iloc[:,-1]\n",
    "x_testSet = testSet.iloc[:,:-1]\n",
    "y_testSet = testSet.iloc[:,-1]\n",
    "LogisReg = LogisReg.fit(x_trainSet,y_trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_trainSet.copy()\n",
    "y = y_trainSet.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(x, weight):\n",
    "    z = np.dot(x, weight.T)\n",
    "    h = 1.0 / (1.0 + np.exp(-z))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x,y,weight):\n",
    "    #z = np.dot(x, weight.T)\n",
    "    N = y.shape[0]\n",
    "    loglike = 1.0/(2*N) * np.sum((h(x,weight)-y)**2)\n",
    "    #loglike = np.sum(y*z - np.log(1+np.exp(z)))\n",
    "    return loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(x,y,weight,learn_rate = 0.1,epsilon = 0.001,maxIteration = 1000):\n",
    "    y = y[:,np.newaxis]\n",
    "    N = y.shape[0]\n",
    "    i = 0\n",
    "    while True:\n",
    "        print('iteration #{:>8d}, loss = {:>8f}'.format(i, cost(x,y,weight)))\n",
    "        weight_prev = weight.copy()\n",
    "        error = (h(x,weight)- y)\n",
    "        weight_new = weight - (learn_rate*1.0)/N * np.sum(error * x, axis=0)\n",
    "        i=i+1\n",
    "        if (np.max(np.abs(weight_new - weight_prev)) < epsilon) or (i > maxIteration):\n",
    "            break\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_trainSet = (x_trainSet - np.mean(x_trainSet, axis=0)) /np.std(x_trainSet, axis=0)\n",
    "x_testSet = (x_testSet - np.mean(x_trainSet, axis=0)) /np.std(x_trainSet, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainSet_aug = np.hstack((np.ones((x_trainSet.shape[0],1)), x_trainSet))\n",
    "x_testSet_aug = np.hstack((np.ones((x_testSet.shape[0],1)), x_testSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #       0, loss = 0.267043\n",
      "iteration #       1, loss = 0.267043\n",
      "iteration #       2, loss = 0.267043\n",
      "iteration #       3, loss = 0.267043\n",
      "iteration #       4, loss = 0.267043\n",
      "iteration #       5, loss = 0.267043\n",
      "iteration #       6, loss = 0.267043\n",
      "iteration #       7, loss = 0.267043\n",
      "iteration #       8, loss = 0.267043\n",
      "iteration #       9, loss = 0.267043\n",
      "iteration #      10, loss = 0.267043\n",
      "iteration #      11, loss = 0.267043\n",
      "iteration #      12, loss = 0.267043\n",
      "iteration #      13, loss = 0.267043\n",
      "iteration #      14, loss = 0.267043\n",
      "iteration #      15, loss = 0.267043\n",
      "iteration #      16, loss = 0.267043\n",
      "iteration #      17, loss = 0.267043\n",
      "iteration #      18, loss = 0.267043\n",
      "iteration #      19, loss = 0.267043\n",
      "iteration #      20, loss = 0.267043\n",
      "iteration #      21, loss = 0.267043\n",
      "iteration #      22, loss = 0.267043\n",
      "iteration #      23, loss = 0.267043\n",
      "iteration #      24, loss = 0.267043\n",
      "iteration #      25, loss = 0.267043\n",
      "iteration #      26, loss = 0.267043\n",
      "iteration #      27, loss = 0.267043\n",
      "iteration #      28, loss = 0.267043\n",
      "iteration #      29, loss = 0.267043\n",
      "iteration #      30, loss = 0.267043\n",
      "iteration #      31, loss = 0.267043\n",
      "iteration #      32, loss = 0.267043\n",
      "iteration #      33, loss = 0.267043\n",
      "iteration #      34, loss = 0.267043\n",
      "iteration #      35, loss = 0.267043\n",
      "iteration #      36, loss = 0.267043\n",
      "iteration #      37, loss = 0.267043\n",
      "iteration #      38, loss = 0.267043\n",
      "iteration #      39, loss = 0.267043\n",
      "iteration #      40, loss = 0.267043\n",
      "iteration #      41, loss = 0.267043\n",
      "iteration #      42, loss = 0.267043\n",
      "iteration #      43, loss = 0.267043\n",
      "iteration #      44, loss = 0.267043\n",
      "iteration #      45, loss = 0.267043\n",
      "iteration #      46, loss = 0.267043\n",
      "iteration #      47, loss = 0.267043\n",
      "iteration #      48, loss = 0.267043\n",
      "iteration #      49, loss = 0.267043\n",
      "iteration #      50, loss = 0.267043\n",
      "iteration #      51, loss = 0.267043\n",
      "iteration #      52, loss = 0.267043\n",
      "iteration #      53, loss = 0.267043\n",
      "iteration #      54, loss = 0.267043\n",
      "iteration #      55, loss = 0.267043\n",
      "iteration #      56, loss = 0.267043\n",
      "iteration #      57, loss = 0.267043\n",
      "iteration #      58, loss = 0.267043\n",
      "iteration #      59, loss = 0.267043\n",
      "iteration #      60, loss = 0.267043\n",
      "iteration #      61, loss = 0.267043\n",
      "iteration #      62, loss = 0.267043\n",
      "iteration #      63, loss = 0.267043\n",
      "iteration #      64, loss = 0.267043\n",
      "iteration #      65, loss = 0.267043\n",
      "iteration #      66, loss = 0.267043\n",
      "iteration #      67, loss = 0.267043\n",
      "iteration #      68, loss = 0.267043\n",
      "iteration #      69, loss = 0.267043\n",
      "iteration #      70, loss = 0.267043\n",
      "iteration #      71, loss = 0.267043\n",
      "iteration #      72, loss = 0.267043\n",
      "iteration #      73, loss = 0.267043\n",
      "iteration #      74, loss = 0.267043\n",
      "iteration #      75, loss = 0.267043\n",
      "iteration #      76, loss = 0.267043\n",
      "iteration #      77, loss = 0.267043\n",
      "iteration #      78, loss = 0.267043\n",
      "iteration #      79, loss = 0.267043\n",
      "iteration #      80, loss = 0.267043\n",
      "iteration #      81, loss = 0.267043\n",
      "iteration #      82, loss = 0.267043\n",
      "iteration #      83, loss = 0.267043\n",
      "iteration #      84, loss = 0.267043\n",
      "iteration #      85, loss = 0.267043\n",
      "iteration #      86, loss = 0.267043\n",
      "iteration #      87, loss = 0.267043\n",
      "iteration #      88, loss = 0.267043\n",
      "iteration #      89, loss = 0.267043\n",
      "iteration #      90, loss = 0.267043\n",
      "iteration #      91, loss = 0.267043\n",
      "iteration #      92, loss = 0.267043\n",
      "iteration #      93, loss = 0.267043\n",
      "iteration #      94, loss = 0.267043\n",
      "iteration #      95, loss = 0.267043\n",
      "iteration #      96, loss = 0.267043\n",
      "iteration #      97, loss = 0.267043\n",
      "iteration #      98, loss = 0.267043\n",
      "iteration #      99, loss = 0.267043\n",
      "iteration #     100, loss = 0.267043\n",
      "iteration #     101, loss = 0.267043\n",
      "iteration #     102, loss = 0.267043\n",
      "iteration #     103, loss = 0.267043\n",
      "iteration #     104, loss = 0.267043\n",
      "iteration #     105, loss = 0.267043\n",
      "iteration #     106, loss = 0.267043\n",
      "iteration #     107, loss = 0.267043\n",
      "iteration #     108, loss = 0.267043\n",
      "iteration #     109, loss = 0.267043\n",
      "iteration #     110, loss = 0.267043\n",
      "iteration #     111, loss = 0.267043\n",
      "iteration #     112, loss = 0.267043\n",
      "iteration #     113, loss = 0.267043\n",
      "iteration #     114, loss = 0.267043\n",
      "iteration #     115, loss = 0.267043\n",
      "iteration #     116, loss = 0.267043\n",
      "iteration #     117, loss = 0.267043\n",
      "iteration #     118, loss = 0.267043\n",
      "iteration #     119, loss = 0.267043\n",
      "iteration #     120, loss = 0.267043\n",
      "iteration #     121, loss = 0.267043\n",
      "iteration #     122, loss = 0.267043\n",
      "iteration #     123, loss = 0.267043\n",
      "iteration #     124, loss = 0.267043\n",
      "iteration #     125, loss = 0.267043\n",
      "iteration #     126, loss = 0.267043\n",
      "iteration #     127, loss = 0.267043\n",
      "iteration #     128, loss = 0.267043\n",
      "iteration #     129, loss = 0.267043\n",
      "iteration #     130, loss = 0.267043\n",
      "iteration #     131, loss = 0.267043\n",
      "iteration #     132, loss = 0.267043\n",
      "iteration #     133, loss = 0.267043\n",
      "iteration #     134, loss = 0.267043\n",
      "iteration #     135, loss = 0.267043\n",
      "iteration #     136, loss = 0.267043\n",
      "iteration #     137, loss = 0.267043\n",
      "iteration #     138, loss = 0.267043\n",
      "iteration #     139, loss = 0.267043\n",
      "iteration #     140, loss = 0.267043\n",
      "iteration #     141, loss = 0.267043\n",
      "iteration #     142, loss = 0.267043\n",
      "iteration #     143, loss = 0.267043\n",
      "iteration #     144, loss = 0.267043\n",
      "iteration #     145, loss = 0.267043\n",
      "iteration #     146, loss = 0.267043\n",
      "iteration #     147, loss = 0.267043\n",
      "iteration #     148, loss = 0.267043\n",
      "iteration #     149, loss = 0.267043\n",
      "iteration #     150, loss = 0.267043\n",
      "iteration #     151, loss = 0.267043\n",
      "iteration #     152, loss = 0.267043\n",
      "iteration #     153, loss = 0.267043\n",
      "iteration #     154, loss = 0.267043\n",
      "iteration #     155, loss = 0.267043\n",
      "iteration #     156, loss = 0.267043\n",
      "iteration #     157, loss = 0.267043\n",
      "iteration #     158, loss = 0.267043\n",
      "iteration #     159, loss = 0.267043\n",
      "iteration #     160, loss = 0.267043\n",
      "iteration #     161, loss = 0.267043\n",
      "iteration #     162, loss = 0.267043\n",
      "iteration #     163, loss = 0.267043\n",
      "iteration #     164, loss = 0.267043\n",
      "iteration #     165, loss = 0.267043\n",
      "iteration #     166, loss = 0.267043\n",
      "iteration #     167, loss = 0.267043\n",
      "iteration #     168, loss = 0.267043\n",
      "iteration #     169, loss = 0.267043\n",
      "iteration #     170, loss = 0.267043\n",
      "iteration #     171, loss = 0.267043\n",
      "iteration #     172, loss = 0.267043\n",
      "iteration #     173, loss = 0.267043\n",
      "iteration #     174, loss = 0.267043\n",
      "iteration #     175, loss = 0.267043\n",
      "iteration #     176, loss = 0.267043\n",
      "iteration #     177, loss = 0.267043\n",
      "iteration #     178, loss = 0.267043\n",
      "iteration #     179, loss = 0.267043\n",
      "iteration #     180, loss = 0.267043\n",
      "iteration #     181, loss = 0.267043\n",
      "iteration #     182, loss = 0.267043\n",
      "iteration #     183, loss = 0.267043\n",
      "iteration #     184, loss = 0.267043\n",
      "iteration #     185, loss = 0.267043\n",
      "iteration #     186, loss = 0.267043\n",
      "iteration #     187, loss = 0.267043\n",
      "iteration #     188, loss = 0.267043\n",
      "iteration #     189, loss = 0.267043\n",
      "iteration #     190, loss = 0.267043\n",
      "iteration #     191, loss = 0.267043\n",
      "iteration #     192, loss = 0.267043\n",
      "iteration #     193, loss = 0.267043\n",
      "iteration #     194, loss = 0.267043\n",
      "iteration #     195, loss = 0.267043\n",
      "iteration #     196, loss = 0.267043\n",
      "iteration #     197, loss = 0.267043\n",
      "iteration #     198, loss = 0.267043\n",
      "iteration #     199, loss = 0.267043\n",
      "iteration #     200, loss = 0.267043\n",
      "iteration #     201, loss = 0.267043\n",
      "iteration #     202, loss = 0.267043\n",
      "iteration #     203, loss = 0.267043\n",
      "iteration #     204, loss = 0.267043\n",
      "iteration #     205, loss = 0.267043\n",
      "iteration #     206, loss = 0.267043\n",
      "iteration #     207, loss = 0.267043\n",
      "iteration #     208, loss = 0.267043\n",
      "iteration #     209, loss = 0.267043\n",
      "iteration #     210, loss = 0.267043\n",
      "iteration #     211, loss = 0.267043\n",
      "iteration #     212, loss = 0.267043\n",
      "iteration #     213, loss = 0.267043\n",
      "iteration #     214, loss = 0.267043\n",
      "iteration #     215, loss = 0.267043\n",
      "iteration #     216, loss = 0.267043\n",
      "iteration #     217, loss = 0.267043\n",
      "iteration #     218, loss = 0.267043\n",
      "iteration #     219, loss = 0.267043\n",
      "iteration #     220, loss = 0.267043\n",
      "iteration #     221, loss = 0.267043\n",
      "iteration #     222, loss = 0.267043\n",
      "iteration #     223, loss = 0.267043\n",
      "iteration #     224, loss = 0.267043\n",
      "iteration #     225, loss = 0.267043\n",
      "iteration #     226, loss = 0.267043\n",
      "iteration #     227, loss = 0.267043\n",
      "iteration #     228, loss = 0.267043\n",
      "iteration #     229, loss = 0.267043\n",
      "iteration #     230, loss = 0.267043\n",
      "iteration #     231, loss = 0.267043\n",
      "iteration #     232, loss = 0.267043\n",
      "iteration #     233, loss = 0.267043\n",
      "iteration #     234, loss = 0.267043\n",
      "iteration #     235, loss = 0.267043\n",
      "iteration #     236, loss = 0.267043\n",
      "iteration #     237, loss = 0.267043\n",
      "iteration #     238, loss = 0.267043\n",
      "iteration #     239, loss = 0.267043\n",
      "iteration #     240, loss = 0.267043\n",
      "iteration #     241, loss = 0.267043\n",
      "iteration #     242, loss = 0.267043\n",
      "iteration #     243, loss = 0.267043\n",
      "iteration #     244, loss = 0.267043\n",
      "iteration #     245, loss = 0.267043\n",
      "iteration #     246, loss = 0.267043\n",
      "iteration #     247, loss = 0.267043\n",
      "iteration #     248, loss = 0.267043\n",
      "iteration #     249, loss = 0.267043\n",
      "iteration #     250, loss = 0.267043\n",
      "iteration #     251, loss = 0.267043\n",
      "iteration #     252, loss = 0.267043\n",
      "iteration #     253, loss = 0.267043\n",
      "iteration #     254, loss = 0.267043\n",
      "iteration #     255, loss = 0.267043\n",
      "iteration #     256, loss = 0.267043\n",
      "iteration #     257, loss = 0.267043\n",
      "iteration #     258, loss = 0.267043\n",
      "iteration #     259, loss = 0.267043\n",
      "iteration #     260, loss = 0.267043\n",
      "iteration #     261, loss = 0.267043\n",
      "iteration #     262, loss = 0.267043\n",
      "iteration #     263, loss = 0.267043\n",
      "iteration #     264, loss = 0.267043\n",
      "iteration #     265, loss = 0.267043\n",
      "iteration #     266, loss = 0.267043\n",
      "iteration #     267, loss = 0.267043\n",
      "iteration #     268, loss = 0.267043\n",
      "iteration #     269, loss = 0.267043\n",
      "iteration #     270, loss = 0.267043\n",
      "iteration #     271, loss = 0.267043\n",
      "iteration #     272, loss = 0.267043\n",
      "iteration #     273, loss = 0.267043\n",
      "iteration #     274, loss = 0.267043\n",
      "iteration #     275, loss = 0.267043\n",
      "iteration #     276, loss = 0.267043\n",
      "iteration #     277, loss = 0.267043\n",
      "iteration #     278, loss = 0.267043\n",
      "iteration #     279, loss = 0.267043\n",
      "iteration #     280, loss = 0.267043\n",
      "iteration #     281, loss = 0.267043\n",
      "iteration #     282, loss = 0.267043\n",
      "iteration #     283, loss = 0.267043\n",
      "iteration #     284, loss = 0.267043\n",
      "iteration #     285, loss = 0.267043\n",
      "iteration #     286, loss = 0.267043\n",
      "iteration #     287, loss = 0.267043\n",
      "iteration #     288, loss = 0.267043\n",
      "iteration #     289, loss = 0.267043\n",
      "iteration #     290, loss = 0.267043\n",
      "iteration #     291, loss = 0.267043\n",
      "iteration #     292, loss = 0.267043\n",
      "iteration #     293, loss = 0.267043\n",
      "iteration #     294, loss = 0.267043\n",
      "iteration #     295, loss = 0.267043\n",
      "iteration #     296, loss = 0.267043\n",
      "iteration #     297, loss = 0.267043\n",
      "iteration #     298, loss = 0.267043\n",
      "iteration #     299, loss = 0.267043\n",
      "iteration #     300, loss = 0.267043\n",
      "iteration #     301, loss = 0.267043\n",
      "iteration #     302, loss = 0.267043\n",
      "iteration #     303, loss = 0.267043\n",
      "iteration #     304, loss = 0.267043\n",
      "iteration #     305, loss = 0.267043\n",
      "iteration #     306, loss = 0.267043\n",
      "iteration #     307, loss = 0.267043\n",
      "iteration #     308, loss = 0.267043\n",
      "iteration #     309, loss = 0.267043\n",
      "iteration #     310, loss = 0.267043\n",
      "iteration #     311, loss = 0.267043\n",
      "iteration #     312, loss = 0.267043\n",
      "iteration #     313, loss = 0.267043\n",
      "iteration #     314, loss = 0.267043\n",
      "iteration #     315, loss = 0.267043\n",
      "iteration #     316, loss = 0.267043\n",
      "iteration #     317, loss = 0.267043\n",
      "iteration #     318, loss = 0.267043\n",
      "iteration #     319, loss = 0.267043\n",
      "iteration #     320, loss = 0.267043\n",
      "iteration #     321, loss = 0.267043\n",
      "iteration #     322, loss = 0.267043\n",
      "iteration #     323, loss = 0.267043\n",
      "iteration #     324, loss = 0.267043\n",
      "iteration #     325, loss = 0.267043\n",
      "iteration #     326, loss = 0.267043\n",
      "iteration #     327, loss = 0.267043\n",
      "iteration #     328, loss = 0.267043\n",
      "iteration #     329, loss = 0.267043\n",
      "iteration #     330, loss = 0.267043\n",
      "iteration #     331, loss = 0.267043\n",
      "iteration #     332, loss = 0.267043\n",
      "iteration #     333, loss = 0.267043\n",
      "iteration #     334, loss = 0.267043\n",
      "iteration #     335, loss = 0.267043\n",
      "iteration #     336, loss = 0.267043\n",
      "iteration #     337, loss = 0.267043\n",
      "iteration #     338, loss = 0.267043\n",
      "iteration #     339, loss = 0.267043\n",
      "iteration #     340, loss = 0.267043\n",
      "iteration #     341, loss = 0.267043\n",
      "iteration #     342, loss = 0.267043\n",
      "iteration #     343, loss = 0.267043\n",
      "iteration #     344, loss = 0.267043\n",
      "iteration #     345, loss = 0.267043\n",
      "iteration #     346, loss = 0.267043\n",
      "iteration #     347, loss = 0.267043\n",
      "iteration #     348, loss = 0.267043\n",
      "iteration #     349, loss = 0.267043\n",
      "iteration #     350, loss = 0.267043\n",
      "iteration #     351, loss = 0.267043\n",
      "iteration #     352, loss = 0.267043\n",
      "iteration #     353, loss = 0.267043\n",
      "iteration #     354, loss = 0.267043\n",
      "iteration #     355, loss = 0.267043\n",
      "iteration #     356, loss = 0.267043\n",
      "iteration #     357, loss = 0.267043\n",
      "iteration #     358, loss = 0.267043\n",
      "iteration #     359, loss = 0.267043\n",
      "iteration #     360, loss = 0.267043\n",
      "iteration #     361, loss = 0.267043\n",
      "iteration #     362, loss = 0.267043\n",
      "iteration #     363, loss = 0.267043\n",
      "iteration #     364, loss = 0.267043\n",
      "iteration #     365, loss = 0.267043\n",
      "iteration #     366, loss = 0.267043\n",
      "iteration #     367, loss = 0.267043\n",
      "iteration #     368, loss = 0.267043\n",
      "iteration #     369, loss = 0.267043\n",
      "iteration #     370, loss = 0.267043\n",
      "iteration #     371, loss = 0.267043\n",
      "iteration #     372, loss = 0.267043\n",
      "iteration #     373, loss = 0.267043\n",
      "iteration #     374, loss = 0.267043\n",
      "iteration #     375, loss = 0.267043\n",
      "iteration #     376, loss = 0.267043\n",
      "iteration #     377, loss = 0.267043\n",
      "iteration #     378, loss = 0.267043\n",
      "iteration #     379, loss = 0.267043\n",
      "iteration #     380, loss = 0.267043\n",
      "iteration #     381, loss = 0.267043\n",
      "iteration #     382, loss = 0.267043\n",
      "iteration #     383, loss = 0.267043\n",
      "iteration #     384, loss = 0.267043\n",
      "iteration #     385, loss = 0.267043\n",
      "iteration #     386, loss = 0.267043\n",
      "iteration #     387, loss = 0.267043\n",
      "iteration #     388, loss = 0.267043\n",
      "iteration #     389, loss = 0.267043\n",
      "iteration #     390, loss = 0.267043\n",
      "iteration #     391, loss = 0.267043\n",
      "iteration #     392, loss = 0.267043\n",
      "iteration #     393, loss = 0.267043\n",
      "iteration #     394, loss = 0.267043\n",
      "iteration #     395, loss = 0.267043\n",
      "iteration #     396, loss = 0.267043\n",
      "iteration #     397, loss = 0.267043\n",
      "iteration #     398, loss = 0.267043\n",
      "iteration #     399, loss = 0.267043\n",
      "iteration #     400, loss = 0.267043\n",
      "iteration #     401, loss = 0.267043\n",
      "iteration #     402, loss = 0.267043\n",
      "iteration #     403, loss = 0.267043\n",
      "iteration #     404, loss = 0.267043\n",
      "iteration #     405, loss = 0.267043\n",
      "iteration #     406, loss = 0.267043\n",
      "iteration #     407, loss = 0.267043\n",
      "iteration #     408, loss = 0.267043\n",
      "iteration #     409, loss = 0.267043\n",
      "iteration #     410, loss = 0.267043\n",
      "iteration #     411, loss = 0.267043\n",
      "iteration #     412, loss = 0.267043\n",
      "iteration #     413, loss = 0.267043\n",
      "iteration #     414, loss = 0.267043\n",
      "iteration #     415, loss = 0.267043\n",
      "iteration #     416, loss = 0.267043\n",
      "iteration #     417, loss = 0.267043\n",
      "iteration #     418, loss = 0.267043\n",
      "iteration #     419, loss = 0.267043\n",
      "iteration #     420, loss = 0.267043\n",
      "iteration #     421, loss = 0.267043\n",
      "iteration #     422, loss = 0.267043\n",
      "iteration #     423, loss = 0.267043\n",
      "iteration #     424, loss = 0.267043\n",
      "iteration #     425, loss = 0.267043\n",
      "iteration #     426, loss = 0.267043\n",
      "iteration #     427, loss = 0.267043\n",
      "iteration #     428, loss = 0.267043\n",
      "iteration #     429, loss = 0.267043\n",
      "iteration #     430, loss = 0.267043\n",
      "iteration #     431, loss = 0.267043\n",
      "iteration #     432, loss = 0.267043\n",
      "iteration #     433, loss = 0.267043\n",
      "iteration #     434, loss = 0.267043\n",
      "iteration #     435, loss = 0.267043\n",
      "iteration #     436, loss = 0.267043\n",
      "iteration #     437, loss = 0.267043\n",
      "iteration #     438, loss = 0.267043\n",
      "iteration #     439, loss = 0.267043\n",
      "iteration #     440, loss = 0.267043\n",
      "iteration #     441, loss = 0.267043\n",
      "iteration #     442, loss = 0.267043\n",
      "iteration #     443, loss = 0.267043\n",
      "iteration #     444, loss = 0.267043\n",
      "iteration #     445, loss = 0.267043\n",
      "iteration #     446, loss = 0.267043\n",
      "iteration #     447, loss = 0.267043\n",
      "iteration #     448, loss = 0.267043\n",
      "iteration #     449, loss = 0.267043\n",
      "iteration #     450, loss = 0.267043\n",
      "iteration #     451, loss = 0.267043\n",
      "iteration #     452, loss = 0.267043\n",
      "iteration #     453, loss = 0.267043\n",
      "iteration #     454, loss = 0.267043\n",
      "iteration #     455, loss = 0.267043\n",
      "iteration #     456, loss = 0.267043\n",
      "iteration #     457, loss = 0.267043\n",
      "iteration #     458, loss = 0.267043\n",
      "iteration #     459, loss = 0.267043\n",
      "iteration #     460, loss = 0.267043\n",
      "iteration #     461, loss = 0.267043\n",
      "iteration #     462, loss = 0.267043\n",
      "iteration #     463, loss = 0.267043\n",
      "iteration #     464, loss = 0.267043\n",
      "iteration #     465, loss = 0.267043\n",
      "iteration #     466, loss = 0.267043\n",
      "iteration #     467, loss = 0.267043\n",
      "iteration #     468, loss = 0.267043\n",
      "iteration #     469, loss = 0.267043\n",
      "iteration #     470, loss = 0.267043\n",
      "iteration #     471, loss = 0.267043\n",
      "iteration #     472, loss = 0.267043\n",
      "iteration #     473, loss = 0.267043\n",
      "iteration #     474, loss = 0.267043\n",
      "iteration #     475, loss = 0.267043\n",
      "iteration #     476, loss = 0.267043\n",
      "iteration #     477, loss = 0.267043\n",
      "iteration #     478, loss = 0.267043\n",
      "iteration #     479, loss = 0.267043\n",
      "iteration #     480, loss = 0.267043\n",
      "iteration #     481, loss = 0.267043\n",
      "iteration #     482, loss = 0.267043\n",
      "iteration #     483, loss = 0.267043\n",
      "iteration #     484, loss = 0.267043\n",
      "iteration #     485, loss = 0.267043\n",
      "iteration #     486, loss = 0.267043\n",
      "iteration #     487, loss = 0.267043\n",
      "iteration #     488, loss = 0.267043\n",
      "iteration #     489, loss = 0.267043\n",
      "iteration #     490, loss = 0.267043\n",
      "iteration #     491, loss = 0.267043\n",
      "iteration #     492, loss = 0.267043\n",
      "iteration #     493, loss = 0.267043\n",
      "iteration #     494, loss = 0.267043\n",
      "iteration #     495, loss = 0.267043\n",
      "iteration #     496, loss = 0.267043\n",
      "iteration #     497, loss = 0.267043\n",
      "iteration #     498, loss = 0.267043\n",
      "iteration #     499, loss = 0.267043\n",
      "iteration #     500, loss = 0.267043\n",
      "iteration #     501, loss = 0.267043\n",
      "iteration #     502, loss = 0.267043\n",
      "iteration #     503, loss = 0.267043\n",
      "iteration #     504, loss = 0.267043\n",
      "iteration #     505, loss = 0.267043\n",
      "iteration #     506, loss = 0.267043\n",
      "iteration #     507, loss = 0.267043\n",
      "iteration #     508, loss = 0.267043\n",
      "iteration #     509, loss = 0.267043\n",
      "iteration #     510, loss = 0.267043\n",
      "iteration #     511, loss = 0.267043\n",
      "iteration #     512, loss = 0.267043\n",
      "iteration #     513, loss = 0.267043\n",
      "iteration #     514, loss = 0.267043\n",
      "iteration #     515, loss = 0.267043\n",
      "iteration #     516, loss = 0.267043\n",
      "iteration #     517, loss = 0.267043\n",
      "iteration #     518, loss = 0.267043\n",
      "iteration #     519, loss = 0.267043\n",
      "iteration #     520, loss = 0.267043\n",
      "iteration #     521, loss = 0.267043\n",
      "iteration #     522, loss = 0.267043\n",
      "iteration #     523, loss = 0.267043\n",
      "iteration #     524, loss = 0.267043\n",
      "iteration #     525, loss = 0.267043\n",
      "iteration #     526, loss = 0.267043\n",
      "iteration #     527, loss = 0.267043\n",
      "iteration #     528, loss = 0.267043\n",
      "iteration #     529, loss = 0.267043\n",
      "iteration #     530, loss = 0.267043\n",
      "iteration #     531, loss = 0.267043\n",
      "iteration #     532, loss = 0.267043\n",
      "iteration #     533, loss = 0.267043\n",
      "iteration #     534, loss = 0.267043\n",
      "iteration #     535, loss = 0.267043\n",
      "iteration #     536, loss = 0.267043\n",
      "iteration #     537, loss = 0.267043\n",
      "iteration #     538, loss = 0.267043\n",
      "iteration #     539, loss = 0.267043\n",
      "iteration #     540, loss = 0.267043\n",
      "iteration #     541, loss = 0.267043\n",
      "iteration #     542, loss = 0.267043\n",
      "iteration #     543, loss = 0.267043\n",
      "iteration #     544, loss = 0.267043\n",
      "iteration #     545, loss = 0.267043\n",
      "iteration #     546, loss = 0.267043\n",
      "iteration #     547, loss = 0.267043\n",
      "iteration #     548, loss = 0.267043\n",
      "iteration #     549, loss = 0.267043\n",
      "iteration #     550, loss = 0.267043\n",
      "iteration #     551, loss = 0.267043\n",
      "iteration #     552, loss = 0.267043\n",
      "iteration #     553, loss = 0.267043\n",
      "iteration #     554, loss = 0.267043\n",
      "iteration #     555, loss = 0.267043\n",
      "iteration #     556, loss = 0.267043\n",
      "iteration #     557, loss = 0.267043\n",
      "iteration #     558, loss = 0.267043\n",
      "iteration #     559, loss = 0.267043\n",
      "iteration #     560, loss = 0.267043\n",
      "iteration #     561, loss = 0.267043\n",
      "iteration #     562, loss = 0.267043\n",
      "iteration #     563, loss = 0.267043\n",
      "iteration #     564, loss = 0.267043\n",
      "iteration #     565, loss = 0.267043\n",
      "iteration #     566, loss = 0.267043\n",
      "iteration #     567, loss = 0.267043\n",
      "iteration #     568, loss = 0.267043\n",
      "iteration #     569, loss = 0.267043\n",
      "iteration #     570, loss = 0.267043\n",
      "iteration #     571, loss = 0.267043\n",
      "iteration #     572, loss = 0.267043\n",
      "iteration #     573, loss = 0.267043\n",
      "iteration #     574, loss = 0.267043\n",
      "iteration #     575, loss = 0.267043\n",
      "iteration #     576, loss = 0.267043\n",
      "iteration #     577, loss = 0.267043\n",
      "iteration #     578, loss = 0.267043\n",
      "iteration #     579, loss = 0.267043\n",
      "iteration #     580, loss = 0.267043\n",
      "iteration #     581, loss = 0.267043\n",
      "iteration #     582, loss = 0.267043\n",
      "iteration #     583, loss = 0.267043\n",
      "iteration #     584, loss = 0.267043\n",
      "iteration #     585, loss = 0.267043\n",
      "iteration #     586, loss = 0.267043\n",
      "iteration #     587, loss = 0.267043\n",
      "iteration #     588, loss = 0.267043\n",
      "iteration #     589, loss = 0.267043\n",
      "iteration #     590, loss = 0.267043\n",
      "iteration #     591, loss = 0.267043\n",
      "iteration #     592, loss = 0.267043\n",
      "iteration #     593, loss = 0.267043\n",
      "iteration #     594, loss = 0.267043\n",
      "iteration #     595, loss = 0.267043\n",
      "iteration #     596, loss = 0.267043\n",
      "iteration #     597, loss = 0.267043\n",
      "iteration #     598, loss = 0.267043\n",
      "iteration #     599, loss = 0.267043\n",
      "iteration #     600, loss = 0.267043\n",
      "iteration #     601, loss = 0.267043\n",
      "iteration #     602, loss = 0.267043\n",
      "iteration #     603, loss = 0.267043\n",
      "iteration #     604, loss = 0.267043\n",
      "iteration #     605, loss = 0.267043\n",
      "iteration #     606, loss = 0.267043\n",
      "iteration #     607, loss = 0.267043\n",
      "iteration #     608, loss = 0.267043\n",
      "iteration #     609, loss = 0.267043\n",
      "iteration #     610, loss = 0.267043\n",
      "iteration #     611, loss = 0.267043\n",
      "iteration #     612, loss = 0.267043\n",
      "iteration #     613, loss = 0.267043\n",
      "iteration #     614, loss = 0.267043\n",
      "iteration #     615, loss = 0.267043\n",
      "iteration #     616, loss = 0.267043\n",
      "iteration #     617, loss = 0.267043\n",
      "iteration #     618, loss = 0.267043\n",
      "iteration #     619, loss = 0.267043\n",
      "iteration #     620, loss = 0.267043\n",
      "iteration #     621, loss = 0.267043\n",
      "iteration #     622, loss = 0.267043\n",
      "iteration #     623, loss = 0.267043\n",
      "iteration #     624, loss = 0.267043\n",
      "iteration #     625, loss = 0.267043\n",
      "iteration #     626, loss = 0.267043\n",
      "iteration #     627, loss = 0.267043\n",
      "iteration #     628, loss = 0.267043\n",
      "iteration #     629, loss = 0.267043\n",
      "iteration #     630, loss = 0.267043\n",
      "iteration #     631, loss = 0.267043\n",
      "iteration #     632, loss = 0.267043\n",
      "iteration #     633, loss = 0.267043\n",
      "iteration #     634, loss = 0.267043\n",
      "iteration #     635, loss = 0.267043\n",
      "iteration #     636, loss = 0.267043\n",
      "iteration #     637, loss = 0.267043\n",
      "iteration #     638, loss = 0.267043\n",
      "iteration #     639, loss = 0.267043\n",
      "iteration #     640, loss = 0.267043\n",
      "iteration #     641, loss = 0.267043\n",
      "iteration #     642, loss = 0.267043\n",
      "iteration #     643, loss = 0.267043\n",
      "iteration #     644, loss = 0.267043\n",
      "iteration #     645, loss = 0.267043\n",
      "iteration #     646, loss = 0.267043\n",
      "iteration #     647, loss = 0.267043\n",
      "iteration #     648, loss = 0.267043\n",
      "iteration #     649, loss = 0.267043\n",
      "iteration #     650, loss = 0.267043\n",
      "iteration #     651, loss = 0.267043\n",
      "iteration #     652, loss = 0.267043\n",
      "iteration #     653, loss = 0.267043\n",
      "iteration #     654, loss = 0.267043\n",
      "iteration #     655, loss = 0.267043\n",
      "iteration #     656, loss = 0.267043\n",
      "iteration #     657, loss = 0.267043\n",
      "iteration #     658, loss = 0.267043\n",
      "iteration #     659, loss = 0.267043\n",
      "iteration #     660, loss = 0.267043\n",
      "iteration #     661, loss = 0.267043\n",
      "iteration #     662, loss = 0.267043\n",
      "iteration #     663, loss = 0.267043\n",
      "iteration #     664, loss = 0.267043\n",
      "iteration #     665, loss = 0.267043\n",
      "iteration #     666, loss = 0.267043\n",
      "iteration #     667, loss = 0.267043\n",
      "iteration #     668, loss = 0.267043\n",
      "iteration #     669, loss = 0.267043\n",
      "iteration #     670, loss = 0.267043\n",
      "iteration #     671, loss = 0.267043\n",
      "iteration #     672, loss = 0.267043\n",
      "iteration #     673, loss = 0.267043\n",
      "iteration #     674, loss = 0.267043\n",
      "iteration #     675, loss = 0.267043\n",
      "iteration #     676, loss = 0.267043\n",
      "iteration #     677, loss = 0.267043\n",
      "iteration #     678, loss = 0.267043\n",
      "iteration #     679, loss = 0.267043\n",
      "iteration #     680, loss = 0.267043\n",
      "iteration #     681, loss = 0.267043\n",
      "iteration #     682, loss = 0.267043\n",
      "iteration #     683, loss = 0.267043\n",
      "iteration #     684, loss = 0.267043\n",
      "iteration #     685, loss = 0.267043\n",
      "iteration #     686, loss = 0.267043\n",
      "iteration #     687, loss = 0.267043\n",
      "iteration #     688, loss = 0.267043\n",
      "iteration #     689, loss = 0.267043\n",
      "iteration #     690, loss = 0.267043\n",
      "iteration #     691, loss = 0.267043\n",
      "iteration #     692, loss = 0.267043\n",
      "iteration #     693, loss = 0.267043\n",
      "iteration #     694, loss = 0.267043\n",
      "iteration #     695, loss = 0.267043\n",
      "iteration #     696, loss = 0.267043\n",
      "iteration #     697, loss = 0.267043\n",
      "iteration #     698, loss = 0.267043\n",
      "iteration #     699, loss = 0.267043\n",
      "iteration #     700, loss = 0.267043\n",
      "iteration #     701, loss = 0.267043\n",
      "iteration #     702, loss = 0.267043\n",
      "iteration #     703, loss = 0.267043\n",
      "iteration #     704, loss = 0.267043\n",
      "iteration #     705, loss = 0.267043\n",
      "iteration #     706, loss = 0.267043\n",
      "iteration #     707, loss = 0.267043\n",
      "iteration #     708, loss = 0.267043\n",
      "iteration #     709, loss = 0.267043\n",
      "iteration #     710, loss = 0.267043\n",
      "iteration #     711, loss = 0.267043\n",
      "iteration #     712, loss = 0.267043\n",
      "iteration #     713, loss = 0.267043\n",
      "iteration #     714, loss = 0.267043\n",
      "iteration #     715, loss = 0.267043\n",
      "iteration #     716, loss = 0.267043\n",
      "iteration #     717, loss = 0.267043\n",
      "iteration #     718, loss = 0.267043\n",
      "iteration #     719, loss = 0.267043\n",
      "iteration #     720, loss = 0.267043\n",
      "iteration #     721, loss = 0.267043\n",
      "iteration #     722, loss = 0.267043\n",
      "iteration #     723, loss = 0.267043\n",
      "iteration #     724, loss = 0.267043\n",
      "iteration #     725, loss = 0.267043\n",
      "iteration #     726, loss = 0.267043\n",
      "iteration #     727, loss = 0.267043\n",
      "iteration #     728, loss = 0.267043\n",
      "iteration #     729, loss = 0.267043\n",
      "iteration #     730, loss = 0.267043\n",
      "iteration #     731, loss = 0.267043\n",
      "iteration #     732, loss = 0.267043\n",
      "iteration #     733, loss = 0.267043\n",
      "iteration #     734, loss = 0.267043\n",
      "iteration #     735, loss = 0.267043\n",
      "iteration #     736, loss = 0.267043\n",
      "iteration #     737, loss = 0.267043\n",
      "iteration #     738, loss = 0.267043\n",
      "iteration #     739, loss = 0.267043\n",
      "iteration #     740, loss = 0.267043\n",
      "iteration #     741, loss = 0.267043\n",
      "iteration #     742, loss = 0.267043\n",
      "iteration #     743, loss = 0.267043\n",
      "iteration #     744, loss = 0.267043\n",
      "iteration #     745, loss = 0.267043\n",
      "iteration #     746, loss = 0.267043\n",
      "iteration #     747, loss = 0.267043\n",
      "iteration #     748, loss = 0.267043\n",
      "iteration #     749, loss = 0.267043\n",
      "iteration #     750, loss = 0.267043\n",
      "iteration #     751, loss = 0.267043\n",
      "iteration #     752, loss = 0.267043\n",
      "iteration #     753, loss = 0.267043\n",
      "iteration #     754, loss = 0.267043\n",
      "iteration #     755, loss = 0.267043\n",
      "iteration #     756, loss = 0.267043\n",
      "iteration #     757, loss = 0.267043\n",
      "iteration #     758, loss = 0.267043\n",
      "iteration #     759, loss = 0.267043\n",
      "iteration #     760, loss = 0.267043\n",
      "iteration #     761, loss = 0.267043\n",
      "iteration #     762, loss = 0.267043\n",
      "iteration #     763, loss = 0.267043\n",
      "iteration #     764, loss = 0.267043\n",
      "iteration #     765, loss = 0.267043\n",
      "iteration #     766, loss = 0.267043\n",
      "iteration #     767, loss = 0.267043\n",
      "iteration #     768, loss = 0.267043\n",
      "iteration #     769, loss = 0.267043\n",
      "iteration #     770, loss = 0.267043\n",
      "iteration #     771, loss = 0.267043\n",
      "iteration #     772, loss = 0.267043\n",
      "iteration #     773, loss = 0.267043\n",
      "iteration #     774, loss = 0.267043\n",
      "iteration #     775, loss = 0.267043\n",
      "iteration #     776, loss = 0.267043\n",
      "iteration #     777, loss = 0.267043\n",
      "iteration #     778, loss = 0.267043\n",
      "iteration #     779, loss = 0.267043\n",
      "iteration #     780, loss = 0.267043\n",
      "iteration #     781, loss = 0.267043\n",
      "iteration #     782, loss = 0.267043\n",
      "iteration #     783, loss = 0.267043\n",
      "iteration #     784, loss = 0.267043\n",
      "iteration #     785, loss = 0.267043\n",
      "iteration #     786, loss = 0.267043\n",
      "iteration #     787, loss = 0.267043\n",
      "iteration #     788, loss = 0.267043\n",
      "iteration #     789, loss = 0.267043\n",
      "iteration #     790, loss = 0.267043\n",
      "iteration #     791, loss = 0.267043\n",
      "iteration #     792, loss = 0.267043\n",
      "iteration #     793, loss = 0.267043\n",
      "iteration #     794, loss = 0.267043\n",
      "iteration #     795, loss = 0.267043\n",
      "iteration #     796, loss = 0.267043\n",
      "iteration #     797, loss = 0.267043\n",
      "iteration #     798, loss = 0.267043\n",
      "iteration #     799, loss = 0.267043\n",
      "iteration #     800, loss = 0.267043\n",
      "iteration #     801, loss = 0.267043\n",
      "iteration #     802, loss = 0.267043\n",
      "iteration #     803, loss = 0.267043\n",
      "iteration #     804, loss = 0.267043\n",
      "iteration #     805, loss = 0.267043\n",
      "iteration #     806, loss = 0.267043\n",
      "iteration #     807, loss = 0.267043\n",
      "iteration #     808, loss = 0.267043\n",
      "iteration #     809, loss = 0.267043\n",
      "iteration #     810, loss = 0.267043\n",
      "iteration #     811, loss = 0.267043\n",
      "iteration #     812, loss = 0.267043\n",
      "iteration #     813, loss = 0.267043\n",
      "iteration #     814, loss = 0.267043\n",
      "iteration #     815, loss = 0.267043\n",
      "iteration #     816, loss = 0.267043\n",
      "iteration #     817, loss = 0.267043\n",
      "iteration #     818, loss = 0.267043\n",
      "iteration #     819, loss = 0.267043\n",
      "iteration #     820, loss = 0.267043\n",
      "iteration #     821, loss = 0.267043\n",
      "iteration #     822, loss = 0.267043\n",
      "iteration #     823, loss = 0.267043\n",
      "iteration #     824, loss = 0.267043\n",
      "iteration #     825, loss = 0.267043\n",
      "iteration #     826, loss = 0.267043\n",
      "iteration #     827, loss = 0.267043\n",
      "iteration #     828, loss = 0.267043\n",
      "iteration #     829, loss = 0.267043\n",
      "iteration #     830, loss = 0.267043\n",
      "iteration #     831, loss = 0.267043\n",
      "iteration #     832, loss = 0.267043\n",
      "iteration #     833, loss = 0.267043\n",
      "iteration #     834, loss = 0.267043\n",
      "iteration #     835, loss = 0.267043\n",
      "iteration #     836, loss = 0.267043\n",
      "iteration #     837, loss = 0.267043\n",
      "iteration #     838, loss = 0.267043\n",
      "iteration #     839, loss = 0.267043\n",
      "iteration #     840, loss = 0.267043\n",
      "iteration #     841, loss = 0.267043\n",
      "iteration #     842, loss = 0.267043\n",
      "iteration #     843, loss = 0.267043\n",
      "iteration #     844, loss = 0.267043\n",
      "iteration #     845, loss = 0.267043\n",
      "iteration #     846, loss = 0.267043\n",
      "iteration #     847, loss = 0.267043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration #     848, loss = 0.267043\n",
      "iteration #     849, loss = 0.267043\n",
      "iteration #     850, loss = 0.267043\n",
      "iteration #     851, loss = 0.267043\n",
      "iteration #     852, loss = 0.267043\n",
      "iteration #     853, loss = 0.267043\n",
      "iteration #     854, loss = 0.267043\n",
      "iteration #     855, loss = 0.267043\n",
      "iteration #     856, loss = 0.267043\n",
      "iteration #     857, loss = 0.267043\n",
      "iteration #     858, loss = 0.267043\n",
      "iteration #     859, loss = 0.267043\n",
      "iteration #     860, loss = 0.267043\n",
      "iteration #     861, loss = 0.267043\n",
      "iteration #     862, loss = 0.267043\n",
      "iteration #     863, loss = 0.267043\n",
      "iteration #     864, loss = 0.267043\n",
      "iteration #     865, loss = 0.267043\n",
      "iteration #     866, loss = 0.267043\n",
      "iteration #     867, loss = 0.267043\n",
      "iteration #     868, loss = 0.267043\n",
      "iteration #     869, loss = 0.267043\n",
      "iteration #     870, loss = 0.267043\n",
      "iteration #     871, loss = 0.267043\n",
      "iteration #     872, loss = 0.267043\n",
      "iteration #     873, loss = 0.267043\n",
      "iteration #     874, loss = 0.267043\n",
      "iteration #     875, loss = 0.267043\n",
      "iteration #     876, loss = 0.267043\n",
      "iteration #     877, loss = 0.267043\n",
      "iteration #     878, loss = 0.267043\n",
      "iteration #     879, loss = 0.267043\n",
      "iteration #     880, loss = 0.267043\n",
      "iteration #     881, loss = 0.267043\n",
      "iteration #     882, loss = 0.267043\n",
      "iteration #     883, loss = 0.267043\n",
      "iteration #     884, loss = 0.267043\n",
      "iteration #     885, loss = 0.267043\n",
      "iteration #     886, loss = 0.267043\n",
      "iteration #     887, loss = 0.267043\n",
      "iteration #     888, loss = 0.267043\n",
      "iteration #     889, loss = 0.267043\n",
      "iteration #     890, loss = 0.267043\n",
      "iteration #     891, loss = 0.267043\n",
      "iteration #     892, loss = 0.267043\n",
      "iteration #     893, loss = 0.267043\n",
      "iteration #     894, loss = 0.267043\n",
      "iteration #     895, loss = 0.267043\n",
      "iteration #     896, loss = 0.267043\n",
      "iteration #     897, loss = 0.267043\n",
      "iteration #     898, loss = 0.267043\n",
      "iteration #     899, loss = 0.267043\n",
      "iteration #     900, loss = 0.267043\n",
      "iteration #     901, loss = 0.267043\n",
      "iteration #     902, loss = 0.267043\n",
      "iteration #     903, loss = 0.267043\n",
      "iteration #     904, loss = 0.267043\n",
      "iteration #     905, loss = 0.267043\n",
      "iteration #     906, loss = 0.267043\n",
      "iteration #     907, loss = 0.267043\n",
      "iteration #     908, loss = 0.267043\n",
      "iteration #     909, loss = 0.267043\n",
      "iteration #     910, loss = 0.267043\n",
      "iteration #     911, loss = 0.267043\n",
      "iteration #     912, loss = 0.267043\n",
      "iteration #     913, loss = 0.267043\n",
      "iteration #     914, loss = 0.267043\n",
      "iteration #     915, loss = 0.267043\n",
      "iteration #     916, loss = 0.267043\n",
      "iteration #     917, loss = 0.267043\n",
      "iteration #     918, loss = 0.267043\n",
      "iteration #     919, loss = 0.267043\n",
      "iteration #     920, loss = 0.267043\n",
      "iteration #     921, loss = 0.267043\n",
      "iteration #     922, loss = 0.267043\n",
      "iteration #     923, loss = 0.267043\n",
      "iteration #     924, loss = 0.267043\n",
      "iteration #     925, loss = 0.267043\n",
      "iteration #     926, loss = 0.267043\n",
      "iteration #     927, loss = 0.267043\n",
      "iteration #     928, loss = 0.267043\n",
      "iteration #     929, loss = 0.267043\n",
      "iteration #     930, loss = 0.267043\n",
      "iteration #     931, loss = 0.267043\n",
      "iteration #     932, loss = 0.267043\n",
      "iteration #     933, loss = 0.267043\n",
      "iteration #     934, loss = 0.267043\n",
      "iteration #     935, loss = 0.267043\n",
      "iteration #     936, loss = 0.267043\n",
      "iteration #     937, loss = 0.267043\n",
      "iteration #     938, loss = 0.267043\n",
      "iteration #     939, loss = 0.267043\n",
      "iteration #     940, loss = 0.267043\n",
      "iteration #     941, loss = 0.267043\n",
      "iteration #     942, loss = 0.267043\n",
      "iteration #     943, loss = 0.267043\n",
      "iteration #     944, loss = 0.267043\n",
      "iteration #     945, loss = 0.267043\n",
      "iteration #     946, loss = 0.267043\n",
      "iteration #     947, loss = 0.267043\n",
      "iteration #     948, loss = 0.267043\n",
      "iteration #     949, loss = 0.267043\n",
      "iteration #     950, loss = 0.267043\n",
      "iteration #     951, loss = 0.267043\n",
      "iteration #     952, loss = 0.267043\n",
      "iteration #     953, loss = 0.267043\n",
      "iteration #     954, loss = 0.267043\n",
      "iteration #     955, loss = 0.267043\n",
      "iteration #     956, loss = 0.267043\n",
      "iteration #     957, loss = 0.267043\n",
      "iteration #     958, loss = 0.267043\n",
      "iteration #     959, loss = 0.267043\n",
      "iteration #     960, loss = 0.267043\n",
      "iteration #     961, loss = 0.267043\n",
      "iteration #     962, loss = 0.267043\n",
      "iteration #     963, loss = 0.267043\n",
      "iteration #     964, loss = 0.267043\n",
      "iteration #     965, loss = 0.267043\n",
      "iteration #     966, loss = 0.267043\n",
      "iteration #     967, loss = 0.267043\n",
      "iteration #     968, loss = 0.267043\n",
      "iteration #     969, loss = 0.267043\n",
      "iteration #     970, loss = 0.267043\n",
      "iteration #     971, loss = 0.267043\n",
      "iteration #     972, loss = 0.267043\n",
      "iteration #     973, loss = 0.267043\n",
      "iteration #     974, loss = 0.267043\n",
      "iteration #     975, loss = 0.267043\n",
      "iteration #     976, loss = 0.267043\n",
      "iteration #     977, loss = 0.267043\n",
      "iteration #     978, loss = 0.267043\n",
      "iteration #     979, loss = 0.267043\n",
      "iteration #     980, loss = 0.267043\n",
      "iteration #     981, loss = 0.267043\n",
      "iteration #     982, loss = 0.267043\n",
      "iteration #     983, loss = 0.267043\n",
      "iteration #     984, loss = 0.267043\n",
      "iteration #     985, loss = 0.267043\n",
      "iteration #     986, loss = 0.267043\n",
      "iteration #     987, loss = 0.267043\n",
      "iteration #     988, loss = 0.267043\n",
      "iteration #     989, loss = 0.267043\n",
      "iteration #     990, loss = 0.267043\n",
      "iteration #     991, loss = 0.267043\n",
      "iteration #     992, loss = 0.267043\n",
      "iteration #     993, loss = 0.267043\n",
      "iteration #     994, loss = 0.267043\n",
      "iteration #     995, loss = 0.267043\n",
      "iteration #     996, loss = 0.267043\n",
      "iteration #     997, loss = 0.267043\n",
      "iteration #     998, loss = 0.267043\n",
      "iteration #     999, loss = 0.267043\n",
      "iteration #    1000, loss = 0.267043\n"
     ]
    }
   ],
   "source": [
    "weight = np.random.randn(1, x_trainSet_aug.shape[1])\n",
    "weight = logisticRegression(x_trainSet_aug, y_trainSet, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Lengths must match to compare",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-3223fe84da2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_testSet_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_testSet\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_testSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logistic regression test error = {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0;31m# as it will broadcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Lengths must match to compare'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Lengths must match to compare"
     ]
    }
   ],
   "source": [
    "y_predict = (h(x_testSet_aug, weight) >= 0.5) [:0]\n",
    "test_error = np.sum(y_testSet != y_predict) / y_testSet.shape[0]\n",
    "print('logistic regression test error = {:.4f}'.format(test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "probability = LogisReg.predict_proba(x_testSet)\n",
    "predicted = LogisReg.predict(x_testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  2]\n",
      " [ 0 59]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_testSet, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
